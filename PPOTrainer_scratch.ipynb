{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Q6rhp1HcIiH4",
        "outputId": "f1d5661f-e32d-4ab5-a3c9-cd4d7a83e2b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'VLM-from-Scratch' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/milistu/VLM-from-Scratch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CzdROerVgYmJ",
        "outputId": "1c992a4e-fb27-4481-b0ab-fa5067b73a1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in ./.env/lib/python3.12/site-packages (2.7.0)\n",
            "Requirement already satisfied: torchvision in ./.env/lib/python3.12/site-packages (0.22.0)\n",
            "Requirement already satisfied: torchaudio in ./.env/lib/python3.12/site-packages (2.7.0)\n",
            "Requirement already satisfied: filelock in ./.env/lib/python3.12/site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in ./.env/lib/python3.12/site-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: setuptools in ./.env/lib/python3.12/site-packages (from torch) (79.0.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./.env/lib/python3.12/site-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in ./.env/lib/python3.12/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./.env/lib/python3.12/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in ./.env/lib/python3.12/site-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./.env/lib/python3.12/site-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./.env/lib/python3.12/site-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./.env/lib/python3.12/site-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./.env/lib/python3.12/site-packages (from torch) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./.env/lib/python3.12/site-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./.env/lib/python3.12/site-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./.env/lib/python3.12/site-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./.env/lib/python3.12/site-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./.env/lib/python3.12/site-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.env/lib/python3.12/site-packages (from torch) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./.env/lib/python3.12/site-packages (from torch) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./.env/lib/python3.12/site-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./.env/lib/python3.12/site-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./.env/lib/python3.12/site-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in ./.env/lib/python3.12/site-packages (from torch) (3.3.0)\n",
            "Requirement already satisfied: numpy in ./.env/lib/python3.12/site-packages (from torchvision) (2.2.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.env/lib/python3.12/site-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.env/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.env/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yYG7vljmJcwC",
        "outputId": "4b52706d-513e-479a-bb18-0caa8d482da8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in ./.env/lib/python3.12/site-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in ./.env/lib/python3.12/site-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.env/lib/python3.12/site-packages (from datasets) (2.2.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in ./.env/lib/python3.12/site-packages (from datasets) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.env/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in ./.env/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in ./.env/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in ./.env/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in ./.env/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in ./.env/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in ./.env/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in ./.env/lib/python3.12/site-packages (from datasets) (3.11.18)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in ./.env/lib/python3.12/site-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in ./.env/lib/python3.12/site-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.env/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.env/lib/python3.12/site-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.env/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.env/lib/python3.12/site-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.env/lib/python3.12/site-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.env/lib/python3.12/site-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./.env/lib/python3.12/site-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.env/lib/python3.12/site-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.env/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.env/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.env/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.env/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.env/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.env/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.env/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.env/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in ./.env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: pandas in ./.env/lib/python3.12/site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in ./.env/lib/python3.12/site-packages (from pandas) (2.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.env/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.env/lib/python3.12/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.env/lib/python3.12/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in ./.env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: transformers in ./.env/lib/python3.12/site-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in ./.env/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./.env/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.env/lib/python3.12/site-packages (from transformers) (2.2.5)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.env/lib/python3.12/site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.env/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./.env/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in ./.env/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.env/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in ./.env/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in ./.env/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.env/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.env/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.env/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.env/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.env/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.env/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: sentencepiece in ./.env/lib/python3.12/site-packages (0.2.0)\n",
            "Requirement already satisfied: tqdm in ./.env/lib/python3.12/site-packages (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install pandas\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install tqdm\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct4lc_6INl5_",
        "outputId": "ed64b29b-9fbe-4ef6-c7ac-2aab462d5e37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory usage: 4253.23 MB\n",
            "Memory usage: 4253.23 MB\n",
            "Memory usage: 4253.23 MB\n",
            "Memory usage: 4253.23 MB\n",
            "Hello world asdasd dasd\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "import os\n",
        "\n",
        "def print_memory_usage():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    mem = process.memory_info().rss / (1024 * 1024)  # in MB\n",
        "    print(f\"Memory usage: {mem:.2f} MB\")\n",
        "\n",
        "print_memory_usage()\n",
        "import sentencepiece as spm\n",
        "print_memory_usage()\n",
        "tokenizer = spm.SentencePieceProcessor(model_file='./spm.model')\n",
        "print_memory_usage()\n",
        "ki = tokenizer.encode(\"Hello world asdasd dasd \")\n",
        "print_memory_usage()\n",
        "print(tokenizer.decode(ki))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1Uft3x3fik8"
      },
      "source": [
        "### Dataset_reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265,
          "referenced_widgets": [
            "a5a36d741cea4450813aee66f42811b2",
            "b97bb17615f049a8a91e128d6048caa6",
            "97aad66242094b76bbc1c9af0777a11f",
            "75389003220547d59674c84adc04ae9a",
            "08699a3acf88491c9519838e5c12d060",
            "bcb5713817e64e5d9c2cefbd420faf3c",
            "9a55b9689e5a45f1b8015f6ead02af1f",
            "a742223ef1a54a54bf65981b3301ddc7",
            "58aea6ef25ec4fa0801cf391d853f810",
            "e1a4ec72204145169b39bf265a8f3ff3",
            "9b3b6beaecfa4c88b4d7c14eed0fb4f6",
            "2f994cffd0c44b3397eddb8d387a5999",
            "174ffde8c3b6469db8cef1f89c5616f4",
            "47eb59e0f83e4aa982b95005a0283682",
            "c1f405116e244128ba592fd13fedc605",
            "c1e9631acf9b4563924da55fbc5a8b28",
            "bdd67c725d3543f3a83926496d5e29f9",
            "c0d3795ca6554386a1798136403f6e23",
            "090dd2df8a4942a282966131431e3e16",
            "55a043b5e11d46218adbd0ba4f929574",
            "e3bb9b8015594bb7a2ad63f52f4672cb",
            "307d8551854744ff8f616c97a978d9b9",
            "58158ff326744386be8763d6fb19bd68",
            "16d18acc4d0f4f5e8093364afe68b7f1",
            "c923b45bcf624511b33150cf433088a9",
            "f9bb9f950a08461bb80960116bf9a994",
            "4b2661cf17d44ccbb7a03003c782c87f",
            "b66026dd389e4994a3b151ea42c7a7ca",
            "95457140a3f5413e9ddd685f98833978",
            "113bc7413aec4e1db4ec9248dccd68ee",
            "2dd9362ff0b8406785180655c753bceb",
            "07bada43d40f48c59ddda3c6068a358a",
            "be8699711c924eb68139c574c0088659"
          ]
        },
        "id": "HCGeuIrKfhA8",
        "outputId": "f21ff82b-9937-4c1a-b246-3cfd238ef778"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Login using e.g. `huggingface-cli login` to access this dataset\n",
        "ds2 = load_dataset(\"MMInstruction/VL-RewardBench\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    test: Dataset({\n",
              "        features: ['id', 'query', 'response', 'image', 'human_ranking', 'models', 'judge', 'rationale', 'query_source', 'ground_truth'],\n",
              "        num_rows: 1250\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds2 = ds2.filter(lambda x: x['human_ranking'] == [0,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1244"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(ds2['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds2 = ds2['test'].map(lambda x: {'image': x['image'], 'prompt': x['query'], 'chosen': x['response'][0], 'rejected': x['response'][1]}\n",
        "                      , remove_columns=['human_ranking', 'response', 'id','models','judge','rationale', 'ground_truth','query_source','query'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image', 'prompt', 'chosen', 'rejected'],\n",
              "    num_rows: 1244\n",
              "})"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "j_DUPT6MHZ2L"
      },
      "outputs": [],
      "source": [
        "# Image preprocessing\n",
        "import transformers\n",
        "import torchvision.transforms as transforms\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "niG3iZHQw3N_",
        "outputId": "70ac7dbe-45fd-4fed-9a63-109ef32f23fa"
      },
      "outputs": [],
      "source": [
        "# Dạng dữ liệu mới: [{'image': PIL.Image, 'prompt': str, 'caption': str}, ...]\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def preprocess2(example):\n",
        "    img_data = example[\"image\"]\n",
        "\n",
        "    # Đảm bảo ảnh là PIL.Image\n",
        "    if isinstance(img_data, Image.Image):\n",
        "        img = img_data.convert(\"RGB\")\n",
        "    elif isinstance(img_data, np.ndarray):\n",
        "        img = Image.fromarray(img_data).convert(\"RGB\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported image format: {type(img_data)}\")\n",
        "\n",
        "    # Transform ảnh sang Tensor (3, 224, 224)\n",
        "    image = image_transform(img)\n",
        "    chosen = example[\"prompt\"] + \" \" + example[\"chosen\"]\n",
        "    rejected = example[\"prompt\"] + \" \" + example[\"rejected\"]\n",
        "\n",
        "    pad_id = tokenizer.pad_id() if tokenizer.pad_id() >= 0 else 0\n",
        "    chosen_input_ids = tokenizer.encode(chosen)\n",
        "    chosen_tokens = chosen_input_ids[:256]\n",
        "    chosen_tokens += [pad_id] * (256 - len(chosen_tokens))\n",
        "    chosen_input_ids = torch.tensor(chosen_tokens, dtype=torch.long)\n",
        "\n",
        "    rejected_input_ids = tokenizer.encode(rejected)\n",
        "    rejected_tokens = rejected_input_ids[:256]\n",
        "    rejected_tokens += [pad_id] * (256 - len(rejected_tokens))\n",
        "    rejected_input_ids = torch.tensor(rejected_tokens, dtype=torch.long)\n",
        "    return {\n",
        "        \"image\": image,\n",
        "        \"chosen_input_ids\": chosen_input_ids,\n",
        "        \"reject_input_ids\": rejected_input_ids\n",
        "    }\n",
        "\n",
        "# # Apply preprocessing\n",
        "# dataset2 = []\n",
        "# for i in range(len(ds2)):\n",
        "#     dataset2.append(preprocess2(ds2[i]))\n",
        "dataset2 = list(map(preprocess2, ds2))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "fy0qVtreGdew"
      },
      "outputs": [],
      "source": [
        "def collate_fn2(batch):\n",
        "    imgs = torch.stack([torch.tensor(item['image']) if not isinstance(item['image'], torch.Tensor) else item['image'] for item in batch])\n",
        "    input_ids = torch.stack([item[\"chosen_input_ids\"] for item in batch])\n",
        "    target_ids = torch.stack([item[\"reject_input_ids\"] for item in batch])\n",
        "    return imgs, input_ids, target_ids\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVL2fDzVh1T7"
      },
      "source": [
        "#1 Base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hYVpTvth4xy",
        "outputId": "e732327e-1ee3-4a00-a22f-e77525d82a12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test passed!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from typing import Tuple\n",
        "# ---\n",
        "class PatchEmbeddings(nn.Module):\n",
        "    def __init__(\n",
        "        self, img_size: int = 96, patch_size: int = 16, hidden_dim: int = 512\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        # Store the input image size, the patch size and hidden dimension\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.num_patches = (self.img_size // self.patch_size) ** 2\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=3,\n",
        "            out_channels=self.hidden_dim,\n",
        "            kernel_size=self.patch_size,\n",
        "            stride=self.patch_size,\n",
        "        )\n",
        "\n",
        "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
        "        X = self.conv(X)\n",
        "        X = X.flatten(2)\n",
        "        X = X.transpose(1, 2)\n",
        "\n",
        "        return X\n",
        "    \n",
        "B, C, H, W = 1, 3, 96, 96  # Batch size, Channels, Height, Width\n",
        "X = torch.randn(B, C, H, W)\n",
        "\n",
        "patch_size = 16\n",
        "hidden_dim = 512\n",
        "\n",
        "patch_embeddings = PatchEmbeddings(\n",
        "    img_size=H, patch_size=patch_size, hidden_dim=hidden_dim\n",
        ")\n",
        "\n",
        "patches = patch_embeddings(X)\n",
        "num_patches = (H // patch_size) ** 2\n",
        "assert patches.shape == (B, num_patches, hidden_dim), \"Output shape is incorrect\"\n",
        "print(\"Test passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKPX-AAaiPZI"
      },
      "source": [
        "## Attention Mechanism"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2Yj9TBFib9t",
        "outputId": "db1db351-314b-42f4-d75f-d696490b4f79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of output tensor: torch.Size([1, 36, 16])\n",
            "Test passed!\n"
          ]
        }
      ],
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_embed: int,\n",
        "        head_size: int,\n",
        "        dropout: float = 0.1,\n",
        "        is_decoder: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # Linear layer for Key projection\n",
        "        self.key = nn.Linear(in_features=n_embed, out_features=head_size, bias=False)\n",
        "\n",
        "        # Linear layer for Query projection\n",
        "        self.query = nn.Linear(in_features=n_embed, out_features=head_size, bias=False)\n",
        "\n",
        "        # Linear layer for Value projection\n",
        "        self.value = nn.Linear(in_features=n_embed, out_features=head_size, bias=False)\n",
        "\n",
        "        # Dropout layer for regularization to prevent overfitting\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Flag indicating wheter the head is used as a decoder\n",
        "        self.is_decoder = is_decoder\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # Get batch size (B), sequence length (T), and embedding dimension (C) from the input tensor\n",
        "        B, T, C = x.shape\n",
        "\n",
        "        # Compute Key, Query, and Value projections\n",
        "        k = self.key(x)  # Shape: (B, T, head_size)\n",
        "        q = self.query(x)  # Shape: (B, T, head_size)\n",
        "        v = self.value(x)  # SHape: (B, T, head_size)\n",
        "\n",
        "        # Compute attention scores by taking the dot product of Query and Key\n",
        "        # and scaling by the square root of the embedding dimension\n",
        "        wei = q @ k.transpose(-2, -1) * (C**-0.5)  # Shape: (B, T, T)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            # If this head is used in the decoder, apply causal mask to the attention scores\n",
        "            # to prevent attention to future positions\n",
        "            tril = torch.tril(torch.ones(T, T, dtype=torch.bool, device=x.device))\n",
        "            wei = wei.masked_fill(mask=tril == 0, value=float(\"-inf\"))\n",
        "\n",
        "        # Apply softmax to the attention scores to obtain attention probabilities\n",
        "        # Sum of probabilities for each row will be 1\n",
        "        wei = F.softmax(input=wei, dim=-1)  # Shape: (B, T, T)\n",
        "\n",
        "        # Apply Dropout to the attention probabilities for regularization\n",
        "        wei = self.dropout(wei)\n",
        "\n",
        "        # Perform a weighted aggregation of values using the attention probabilities\n",
        "        out = wei @ v  # Shape: (B, T, head_size)\n",
        "\n",
        "        return out\n",
        "B, T, C = patches.shape  # Batch size, Sequence length, Embedding dimension\n",
        "head_size = 16  # Size of the attention head\n",
        "\n",
        "head = Head(n_embed=C, head_size=head_size)\n",
        "output = head(patches)\n",
        "print(f\"Shape of output tensor: {output.shape}\")\n",
        "assert output.shape == (B, T, head_size), \"Output shape is incorrect\"\n",
        "print(\"Test passed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l84_wBB5jZk6",
        "outputId": "82052f9b-fe35-47de-e3f2-40199e2fac59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of output tensor: torch.Size([1, 36, 512])\n",
            "Test passed!\n"
          ]
        }
      ],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_embed: int,\n",
        "        num_heads: int,\n",
        "        dropout: float = 0.1,\n",
        "        is_decoder: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # Ensure that the embedding dimension is divisible by the number of heads\n",
        "        assert n_embed % num_heads == 0, \"n_embed must be divisible by num_heads!\"\n",
        "\n",
        "        # Create a ModuleList of attention heads\n",
        "        self.heads = nn.ModuleList(\n",
        "            modules=[\n",
        "                Head(\n",
        "                    n_embed=n_embed,\n",
        "                    head_size=n_embed // num_heads,\n",
        "                    dropout=dropout,\n",
        "                    is_decoder=is_decoder,\n",
        "                )\n",
        "                for _ in range(num_heads)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Linear layer for projecting the concatenated head outputs\n",
        "        self.proj = nn.Linear(in_features=n_embed, out_features=n_embed)\n",
        "\n",
        "        # Dropout layer for regularization\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # Apply each attention head to the input tensor\n",
        "        head_outputs = [\n",
        "            h(x) for h in self.heads\n",
        "        ]  # Shape: num_heads * (B, T, head_size)\n",
        "\n",
        "        # Concatenate the outputs from all heads along the last dimension\n",
        "        out = torch.cat(tensors=head_outputs, dim=-1)  # Shape: (B, T, m_embed)\n",
        "\n",
        "        # Apply the projection layer to the concatenated outputs\n",
        "        out = self.proj(out)  # Shape: (B, T, m_embed)\n",
        "\n",
        "        # Apply Dropout to the projected outputs for regularization\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        return out\n",
        "num_heads = 2\n",
        "dropout = 0.1\n",
        "mha = MultiHeadAttention(n_embed=C, num_heads=num_heads, dropout=dropout)\n",
        "output = mha(patches)\n",
        "print(f\"Shape of output tensor: {output.shape}\")\n",
        "assert output.shape == (B, T, C), \"Output shape is incorrect\"\n",
        "print(\"Test passed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq8hRWLWjx1J",
        "outputId": "c49dc79c-e33e-49bf-8b6d-353517e20ee4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of output tensor: torch.Size([1, 36, 512])\n",
            "Test passed!\n"
          ]
        }
      ],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(\n",
        "        self, n_embed: int, dropout: float = 0.1, is_decoder: bool = False\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # Define the layers of the MLP\n",
        "        layers = [\n",
        "            # First linear layer that expands the input dimension from n_embed to 4 * n_embed\n",
        "            nn.Linear(in_features=n_embed, out_features=4 * n_embed),\n",
        "            # Activation function: ReLU if is_decoder is True, else GELU\n",
        "            nn.ReLU() if is_decoder else nn.GELU(),\n",
        "            # Second linear layer that projects the intermediate dimension back to n_embed\n",
        "            nn.Linear(in_features=4 * n_embed, out_features=n_embed),\n",
        "            # Dropout layer for regularization\n",
        "            nn.Dropout(p=dropout),\n",
        "        ]\n",
        "\n",
        "        # Create the MLP as a sequence of layers\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # Pass the input through the MLP layers\n",
        "        return self.net(x)\n",
        "dropout = 0.1\n",
        "mlp = MLP(n_embed=C, dropout=dropout)\n",
        "output = mlp(output)  # Previous output of the Multihead Attention\n",
        "print(f\"Shape of output tensor: {output.shape}\")\n",
        "assert output.shape == (B, T, C), \"Output shape is incorrect\"\n",
        "print(\"Test passed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdUM6w_ij5ZZ",
        "outputId": "df4a9263-45a6-432b-8618-b9939be2cb7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of output tensor: torch.Size([1, 36, 512])\n",
            "Test passed!\n"
          ]
        }
      ],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_embed: int,\n",
        "        num_heads: int,\n",
        "        dropout: float = 0.1,\n",
        "        is_decoder: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # Layer normalization for the input to the attention layer\n",
        "        self.ln1 = nn.LayerNorm(normalized_shape=n_embed)\n",
        "\n",
        "        # Multi-head attention module\n",
        "        self.mhattn = MultiHeadAttention(\n",
        "            n_embed=n_embed, num_heads=num_heads, dropout=dropout, is_decoder=is_decoder\n",
        "        )\n",
        "\n",
        "        # Layer normalization for the input to the FFN\n",
        "        self.ln2 = nn.LayerNorm(normalized_shape=n_embed)\n",
        "\n",
        "        # Feed-forward neural network (FFN)\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(in_features=n_embed, out_features=4 * n_embed),\n",
        "            nn.GELU(),  # Activation function\n",
        "            nn.Linear(\n",
        "                in_features=4 * n_embed, out_features=n_embed\n",
        "            ),  # Projection back to the original dimension\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # Saving the input for residual connection\n",
        "        original_x = x\n",
        "\n",
        "        # Apply layer normalization to the input\n",
        "        x = self.ln1(x)\n",
        "\n",
        "        # Apply multi-head attention\n",
        "        mhattn_output = self.mhattn(x)\n",
        "\n",
        "        # Add the residual connection (original input) to the attention output\n",
        "        x = original_x + mhattn_output\n",
        "\n",
        "        # Apply later normalization to the input to the FFN\n",
        "        x = self.ln2(x)\n",
        "\n",
        "        # Apply the FFN\n",
        "        ffn_output = self.ffn(x)\n",
        "\n",
        "        # Apply the residual connection (input to the FFN) to the FFN output\n",
        "        x = x + ffn_output\n",
        "\n",
        "        return x\n",
        "num_heads = 2\n",
        "dropout = 0.1\n",
        "block = Block(n_embed=C, num_heads=num_heads, dropout=dropout)\n",
        "output = block(patches)\n",
        "print(f\"Shape of output tensor: {output.shape}\")\n",
        "assert output.shape == (B, T, C), \"Output shape is incorrect\"\n",
        "print(\"Test passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB5AiL6rkFXu"
      },
      "source": [
        "## Vit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4tVh4NGkHRe",
        "outputId": "41151846-0c1d-44a8-af01-92c3ee2c57df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output shape: torch.Size([2, 64])\n",
            "Test passed!\n"
          ]
        }
      ],
      "source": [
        "class ViT(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_size: int,\n",
        "        patch_size: int,\n",
        "        num_hiddens: int,\n",
        "        num_heads: int,\n",
        "        num_blocks: int,\n",
        "        emb_dropout: float,\n",
        "        block_dropout: float,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # Patch embedding layer to convert the input image into patches\n",
        "        self.patch_embedding = PatchEmbeddings(\n",
        "            img_size=img_size, patch_size=patch_size, hidden_dim=num_hiddens\n",
        "        )\n",
        "\n",
        "        # Learnable classification token\n",
        "        self.cls_token = nn.Parameter(data=torch.zeros(size=(1, 1, num_hiddens)))\n",
        "\n",
        "        # Calculate the number of patches\n",
        "        num_patches = (img_size // patch_size) ** 2\n",
        "\n",
        "        # Learnable position embedding\n",
        "        self.pos_embedding = nn.Parameter(\n",
        "            data=torch.randn(size=(1, num_patches + 1, num_hiddens))\n",
        "        )\n",
        "\n",
        "        # Dropout layer for the embeddings\n",
        "        self.dropout = nn.Dropout(p=emb_dropout)\n",
        "\n",
        "        # Stack of transformer blocks\n",
        "        self.blocks = nn.ModuleList(\n",
        "            [\n",
        "                Block(\n",
        "                    n_embed=num_hiddens,\n",
        "                    num_heads=num_heads,\n",
        "                    dropout=block_dropout,\n",
        "                    is_decoder=False,\n",
        "                )\n",
        "                for _ in range(num_blocks)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Layer normalization for the final representation\n",
        "        self.layer_norm = nn.LayerNorm(normalized_shape=num_hiddens)\n",
        "\n",
        "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
        "        # Convert the input image into patch embeddings\n",
        "        x = self.patch_embedding(X)  # Shape: (B, num_patches, num_hiddens)\n",
        "\n",
        "        # Expand the classification token to match the batch size\n",
        "        cls_tokens = self.cls_token.expand(\n",
        "            x.shape[0], -1, -1\n",
        "        )  # Shape: (B, 1, num_hiddens)\n",
        "\n",
        "        # Concatenate the classification token with the patch embeddings\n",
        "        x = torch.cat(\n",
        "            tensors=(cls_tokens, x), dim=1\n",
        "        )  # Shape: (B, num_patches + 1, num_hiddens)\n",
        "\n",
        "        # Add the position embedding to the patch embeddings\n",
        "        x += self.pos_embedding  # Shape: (B, num_patches + 1, num_hiddens)\n",
        "\n",
        "        # Apply dropout to the embeddings\n",
        "        x = self.dropout(x)  # Shape: (B, num_patches + 1, num_hiddens)\n",
        "\n",
        "        # Pass the embeddings through the transformer blocks\n",
        "        for block in self.blocks:\n",
        "            x = block(x)  # Shape: (B, num_patches + 1, num_hiddens)\n",
        "\n",
        "        # Apply layer normalization to the `[CLS]` token's final representation\n",
        "        x = self.layer_norm(x[:, 0])  # Shape: (B, num_hiddens)\n",
        "\n",
        "        return x\n",
        "B, C, H, W = 2, 3, 96, 96  # Batch size, Channels, Height, Width\n",
        "X = torch.randn(B, C, H, W)\n",
        "vit = ViT(\n",
        "    img_size=H,\n",
        "    patch_size=16,\n",
        "    num_hiddens=64,\n",
        "    num_heads=2,\n",
        "    num_blocks=2,\n",
        "    emb_dropout=0.1,\n",
        "    block_dropout=0.1,\n",
        ")\n",
        "output = vit(X)\n",
        "print(f\"Output shape: {output.shape}\")\n",
        "assert output.shape == (B, 64), \"Output shape is incorrect\"\n",
        "print(\"Test passed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCc048SrkSaL",
        "outputId": "4a15a3a6-d1fa-4b0f-ce14-fcff3f89a642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output shape: torch.Size([2, 64])\n",
            "Test passed!\n"
          ]
        }
      ],
      "source": [
        "class MultiModalProjector(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_embed: int,\n",
        "        img_embed_dim: int,\n",
        "        dropout: float = 0.1,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # Define the projection network\n",
        "        self.net = nn.Sequential(\n",
        "            # Linear layer to expand the image embedding dimension\n",
        "            nn.Linear(in_features=img_embed_dim, out_features=4 * img_embed_dim),\n",
        "            # GELU activation function\n",
        "            nn.GELU(),\n",
        "            # Linear layer to project the expanded image embeddings to the text embedding dimension\n",
        "            nn.Linear(in_features=4 * img_embed_dim, out_features=n_embed),\n",
        "            # Dropout layer for regularization\n",
        "            nn.Dropout(p=dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # Pass the input through the projection network\n",
        "        x = self.net(x)  # Shape: (B, img_embed_dim) --> (B, n_embed)\n",
        "        return x\n",
        "B, n_embed, img_embed_dim = 2, 64, 128\n",
        "X = torch.randn(size=(B, img_embed_dim))\n",
        "\n",
        "projector = MultiModalProjector(\n",
        "    n_embed=n_embed, img_embed_dim=img_embed_dim, dropout=0.1\n",
        ")\n",
        "output = projector(X)\n",
        "print(f\"Output shape: {output.shape}\")\n",
        "assert output.shape == (B, n_embed), \"Output shape is incorrect\"\n",
        "print(\"Test passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xZXUMAIkdZa"
      },
      "source": [
        "## Decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "gU3Qc8j9kbc5"
      },
      "outputs": [],
      "source": [
        "class DecoderLanguageModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_embed: int,\n",
        "        img_embed_dim: int,\n",
        "        vocab_size: int,\n",
        "        num_heads: int,\n",
        "        n_layer: int,\n",
        "        use_images: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.use_images = use_images\n",
        "\n",
        "        # Token embedding table\n",
        "        self.token_embedding_table = nn.Embedding(\n",
        "            num_embeddings=vocab_size, embedding_dim=n_embed\n",
        "        )\n",
        "\n",
        "        # Position embedding table\n",
        "        self.position_embedding_table = nn.Embedding(\n",
        "            num_embeddings=1000, embedding_dim=n_embed\n",
        "        )\n",
        "\n",
        "        if use_images:\n",
        "            # Image projection layer to align image embeddings with text embeddings\n",
        "            self.image_projection = MultiModalProjector(\n",
        "                n_embed=n_embed, img_embed_dim=img_embed_dim\n",
        "            )\n",
        "\n",
        "        # Stack of transformer decoder blocks\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[\n",
        "                Block(n_embed=n_embed, num_heads=num_heads, is_decoder=True)\n",
        "                for _ in range(n_layer)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Final layer normalization\n",
        "        self.ln_f = nn.LayerNorm(normalized_shape=n_embed)\n",
        "\n",
        "        # Language modeling head\n",
        "        self.lm_head = nn.Linear(in_features=n_embed, out_features=vocab_size)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        idx: torch.Tensor,\n",
        "        img_embeds: torch.Tensor = None,\n",
        "        targets: torch.Tensor = None,\n",
        "    ) -> torch.Tensor:\n",
        "        # Get token embeddings from the input indices\n",
        "        tok_emb = self.token_embedding_table(idx)\n",
        "\n",
        "        if self.use_images:\n",
        "            # Project and concatenate image embeddings with token embeddings\n",
        "            img_emb = self.image_projection(img_embeds).unsqueeze(1)\n",
        "            tok_emb = torch.cat([img_emb, tok_emb], dim=1)\n",
        "\n",
        "        # Get position embeddings\n",
        "        pos_emb = self.position_embedding_table(\n",
        "            torch.arange(tok_emb.size(1), device=idx.device)\n",
        "        )\n",
        "\n",
        "        # Add position embeddings to token embeddings\n",
        "        x = tok_emb + pos_emb\n",
        "\n",
        "        # Pass through the transformer decoder blocks\n",
        "        x = self.blocks(x)\n",
        "\n",
        "        # Apply final layer normalization\n",
        "        x = self.ln_f(x)\n",
        "\n",
        "        # Get the logits from the language modeling head\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is not None:\n",
        "            if self.use_images and img_embeds is not None:\n",
        "                # Prepare targets by concatenating a dummy target for the image embedding\n",
        "                batch_size = idx.size(0)\n",
        "                targets = torch.cat(\n",
        "                    [\n",
        "                        torch.full(\n",
        "                            (batch_size, 1), -100, dtype=torch.long, device=idx.device\n",
        "                        ),\n",
        "                        targets,\n",
        "                    ],\n",
        "                    dim=1,\n",
        "                )\n",
        "\n",
        "            # Compute the cross-entropy loss\n",
        "            loss = F.cross_entropy(\n",
        "                input=logits.view(-1, logits.size(-1)),\n",
        "                target=targets.view(-1),\n",
        "                ignore_index=-100,\n",
        "            )\n",
        "            return logits, loss\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def generate(\n",
        "        self, idx: torch.Tensor, img_embeds: torch.Tensor, max_new_tokens: int\n",
        "    ) -> torch.Tensor:\n",
        "        # Get the batch size and sequence length\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # Initialize the generated sequence with the input indices\n",
        "        generated = idx\n",
        "        tok_emb = self.token_embedding_table(idx)\n",
        "\n",
        "        if self.use_images and img_embeds is not None:\n",
        "            # Project and concatenate image embeddings with token embeddings\n",
        "            img_emb = self.image_projection(img_embeds).unsqueeze(1)\n",
        "            current_output = torch.cat([img_emb, tok_emb], dim=1)\n",
        "        else:\n",
        "            current_output = tok_emb\n",
        "\n",
        "        # Generate new tokens iteratevely\n",
        "        for i in range(max_new_tokens):\n",
        "            # Get the current sequence length\n",
        "            T_current = current_output.shape[1]\n",
        "\n",
        "            # Get position embeddings for the current sequence length\n",
        "            current_pos_emb = self.position_embedding_table(\n",
        "                torch.arange(T_current, device=idx.device)\n",
        "            ).unsqueeze(0)\n",
        "\n",
        "            # Add position embeddings to the current output\n",
        "            current_output += current_pos_emb\n",
        "\n",
        "            # Pass through the transformer decoder blocks\n",
        "            for block in self.blocks:\n",
        "                current_output = block(current_output)\n",
        "\n",
        "            # Get the logits for the last token\n",
        "            logits = self.lm_head(current_output[:, -1, :])\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "            # Sample the next token based on the probability\n",
        "            idx_next = torch.multinomial(input=probs, num_samples=1)\n",
        "\n",
        "            # Concatenate the generated token to the generated sequence\n",
        "            generated = torch.cat([generated, idx_next], dim=1)\n",
        "\n",
        "            # Get the embeddings for the generated token\n",
        "            idx_next_emb = self.token_embedding_table(idx_next)\n",
        "\n",
        "            # Concatenate the generated token embeddings to the current output\n",
        "            current_output = torch.cat([current_output, idx_next_emb], dim=1)\n",
        "\n",
        "        return generated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjiTh2QoCBuc",
        "outputId": "c583ce21-4eac-4c54-9b5f-7de4b34d02d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[-1.9717,  0.2538,  1.5162,  0.3013,  1.2697, -0.1159, -0.1931,\n",
            "           0.7020, -0.0179,  2.0949],\n",
            "         [-1.0747, -0.8158,  0.9019, -0.9119, -1.1437, -1.2513,  2.2801,\n",
            "           0.3489, -0.1461,  0.8202],\n",
            "         [ 0.2504, -0.5564, -1.3196, -1.0037, -0.9294,  0.6707,  1.2467,\n",
            "           2.3581,  0.2327,  0.4532],\n",
            "         [-1.5703,  0.7633,  0.2696,  1.0340,  0.6696,  0.3486,  0.0156,\n",
            "           0.0284, -0.5442,  2.0323],\n",
            "         [ 0.3278,  0.3139, -1.7571,  2.7767,  1.0911, -0.8164, -0.2428,\n",
            "           0.5178, -1.1838, -1.3295]],\n",
            "\n",
            "        [[-0.6479, -0.0668,  0.3694, -0.6553,  1.0205, -1.1558, -0.5911,\n",
            "          -0.1538, -0.9652,  0.0478],\n",
            "         [ 0.2931,  1.3820,  1.0517,  0.2992, -1.0632, -2.0147,  0.8976,\n",
            "          -0.9075,  0.1654, -1.2044],\n",
            "         [ 0.5730,  0.0580, -0.7704, -0.1815,  0.5685,  0.7436, -0.5249,\n",
            "          -2.2182,  0.1672,  0.0692],\n",
            "         [-0.8057, -0.1025,  0.7853,  1.0227,  1.3004,  1.6454, -0.6180,\n",
            "          -0.5352,  0.2914,  2.0800],\n",
            "         [ 0.3751, -0.2031,  1.5316,  0.5199, -0.2807, -1.8512,  2.4163,\n",
            "           2.7420, -0.1389, -0.0439]]])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10])\n",
            "Loss: 2.983717441558838\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Simulated inputs\n",
        "batch_size = 2\n",
        "seq_len = 4\n",
        "vocab_size = 10\n",
        "\n",
        "# Fake target labels (batch_size x seq_len)\n",
        "targets = torch.tensor([\n",
        "    [1, 2, 3, 4],\n",
        "    [2, 3, 4, 5]\n",
        "], dtype=torch.long)  # shape: [2, 4]\n",
        "\n",
        "# Dummy index tensor for alignment (same batch_size)\n",
        "idx = torch.arange(batch_size)\n",
        "\n",
        "# Simulated logits output from a model (batch_size x seq_len+1 x vocab_size)\n",
        "# We assume image embeddings are used, so seq_len + 1\n",
        "logits = torch.randn(batch_size, seq_len + 1, vocab_size)  # shape: [2, 5, 10]\n",
        "print(logits)\n",
        "\n",
        "# Add dummy target token for image embedding (-100 will be ignored in loss)\n",
        "targets = torch.cat(\n",
        "    [\n",
        "        torch.full(\n",
        "            (batch_size, 1), -100, dtype=torch.long, device=targets.device\n",
        "        ),\n",
        "        targets\n",
        "    ],\n",
        "    dim=1\n",
        ")  # shape: [2, 5]\n",
        "\n",
        "print(logits.view(-1, vocab_size).shape)\n",
        "print(targets.view(-1).shape)\n",
        "\n",
        "# Confirm shapes match\n",
        "assert logits.shape[:2] == targets.shape, f\"Shape mismatch: {logits.shape[:2]} vs {targets.shape}\"\n",
        "\n",
        "# Compute cross-entropy loss\n",
        "loss = F.cross_entropy(\n",
        "    input=logits.view(-1, vocab_size),  # shape: [2*5, 10]\n",
        "    target=targets.view(-1),            # shape: [2*5]\n",
        "    ignore_index=-100\n",
        ")\n",
        "\n",
        "print(\"Loss:\", loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tchiqNzNCEI0",
        "outputId": "d9711cf1-5948-4d5e-ce9f-2777a2350f83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8U1tBG9CI3u",
        "outputId": "f6a9c81c-08b0-4708-92f3-7231e6692db8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logits shape: torch.Size([10, 51, 1000]), Loss: 7.060498237609863\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated sequence shape: torch.Size([10, 70])\n"
          ]
        }
      ],
      "source": [
        "n_embed, img_embed_dim, vocab_size, num_heads, n_layer = 128, 256, 1000, 8, 6\n",
        "# `n_layer` is used to represent number of decoder transformer blocks and num_blocks for the vision encoder to avoid confusion\n",
        "model = DecoderLanguageModel(\n",
        "    n_embed=n_embed,\n",
        "    img_embed_dim=img_embed_dim,\n",
        "    vocab_size=vocab_size,\n",
        "    num_heads=num_heads,\n",
        "    n_layer=n_layer,\n",
        "    use_images=True,\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "# Dummy input\n",
        "B, T = 10, 50\n",
        "idx = torch.randint(low=0, high=vocab_size, size=(B, T)).to(device)\n",
        "image_embeds = torch.randn(B, 256).to(device)  # Assume img_embed_dim is 256\n",
        "\n",
        "targets = torch.randint(0, vocab_size, (B, T)).to(\n",
        "    device\n",
        ")  # Only if you want to compute loss\n",
        "\n",
        "# Test forward pass\n",
        "# Check if you need to calculate loss by providing targets\n",
        "if targets is not None:\n",
        "    logits, loss = model(idx, image_embeds, targets)\n",
        "    print(f\"Logits shape: {logits.shape}, Loss: {loss}\")\n",
        "else:\n",
        "    logits = model(idx, image_embeds)  # Call without targets\n",
        "    print(f\"Logits shape: {logits.shape}\")\n",
        "\n",
        "# Test generation\n",
        "generated = model.generate(idx, image_embeds, max_new_tokens=20)\n",
        "print(f\"Generated sequence shape: {generated.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9Px6PhhCVvC"
      },
      "source": [
        "## Put everything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p6mmeEBCLDg",
        "outputId": "b1305a76-905f-46f7-a59c-e39cf9f609d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on device: cpu\n"
          ]
        }
      ],
      "source": [
        "class VisionLanguageModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_embed: int,\n",
        "        img_embed_dim: int,\n",
        "        vocab_size: int,\n",
        "        n_layer: int,\n",
        "        img_size: int,\n",
        "        patch_size: int,\n",
        "        num_heads: int,\n",
        "        num_blocks: int,\n",
        "        emb_dropout: float,\n",
        "        block_dropout: float,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # Set num_hiddens equal to img_embed_dim\n",
        "        num_hiddens = img_embed_dim\n",
        "\n",
        "        # Assert that num_hiddens is divisible by num_heads\n",
        "        assert num_hiddens % num_heads == 0, ValueError(\n",
        "            \"num_hiddens must be divisible by num_heads!\"\n",
        "        )\n",
        "\n",
        "        # Initialize the Vision Transformer (ViT) encoder\n",
        "        self.vision_encoder = ViT(\n",
        "            img_size=img_size,\n",
        "            patch_size=patch_size,\n",
        "            num_hiddens=num_hiddens,\n",
        "            num_heads=num_heads,\n",
        "            num_blocks=num_blocks,\n",
        "            emb_dropout=emb_dropout,\n",
        "            block_dropout=block_dropout,\n",
        "        )\n",
        "\n",
        "        # Initialize the Language Model Decoder (DecoderLanguageModel)\n",
        "        self.decoder = DecoderLanguageModel(\n",
        "            n_embed=n_embed,\n",
        "            img_embed_dim=img_embed_dim,\n",
        "            vocab_size=vocab_size,\n",
        "            num_heads=num_heads,\n",
        "            n_layer=n_layer,\n",
        "            use_images=True,\n",
        "        )\n",
        "\n",
        "    def _check_image_embeddings(self, image_embeds: torch.Tensor) -> None:\n",
        "        \"\"\"Chek if image embeddings are valid.\"\"\"\n",
        "        if image_embeds.nelement() == 0 or image_embeds.shape[1] == 0:\n",
        "            raise ValueError(\n",
        "                \"Something is wrong with the ViT model. It's returning an empty tensor or the embedding dimension is empty.\"\n",
        "            )\n",
        "\n",
        "    def forward(\n",
        "        self, img_array: torch.Tensor, idx: torch.Tensor, targets: torch.Tensor = None\n",
        "    ) -> torch.Tensor | Tuple[torch.Tensor, torch.Tensor]:\n",
        "        # Get the image embeddings from the Vision Encoder\n",
        "        image_embeds = self.vision_encoder(img_array)\n",
        "\n",
        "        # Check if image embeddings are valid\n",
        "        self._check_image_embeddings(image_embeds)\n",
        "\n",
        "        if targets is not None:\n",
        "            # If targets are provided, compute the logits and loss\n",
        "            logits, loss = self.decoder(idx, image_embeds, targets)\n",
        "            return logits, loss\n",
        "        else:\n",
        "            # If targets are not provided, compute only the logits\n",
        "            logits = self.decoder(idx, image_embeds)\n",
        "            return logits\n",
        "\n",
        "    def generate(\n",
        "        self, img_array: torch.Tensor, idx: torch.Tensor, max_new_tokens: int\n",
        "    ) -> torch.Tensor:\n",
        "        # Get the image embeddings from the Vision Encoder\n",
        "        image_embeds = self.vision_encoder(img_array)\n",
        "\n",
        "        # Check if image embeddings are valid\n",
        "        self._check_image_embeddings(image_embeds)\n",
        "\n",
        "        # Generate new tokens using the Language Model Decoder\n",
        "        generated_tokens = self.decoder.generate(\n",
        "            idx=idx, img_embeds=image_embeds, max_new_tokens=max_new_tokens\n",
        "        )\n",
        "        return generated_tokens\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "print(f\"Running on device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdR2tuTwCc7E",
        "outputId": "99f1ed21-08c3-49de-8101-9a98fd3729e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output from initialization forward pass: tensor([[[-0.6109, -0.6073,  0.3757,  ...,  0.7373, -0.3653,  0.2470],\n",
            "         [-1.0122,  0.9071,  1.0353,  ...,  0.7759, -0.5381, -0.6131],\n",
            "         [-0.1407, -0.8277,  0.5460,  ...,  1.3337, -0.1829,  0.0894],\n",
            "         ...,\n",
            "         [-0.6025,  1.1103,  1.0675,  ..., -0.9632, -0.1273, -0.4883],\n",
            "         [-0.0513, -1.3979, -0.6534,  ...,  0.4909, -0.4671, -0.0014],\n",
            "         [ 0.3264,  0.5641, -0.2365,  ...,  0.5534, -1.0300,  0.7593]]],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "n_embed, num_hiddens, vocab_size, num_heads, n_layer = 128, 512, 1000, 8, 8\n",
        "image_embed_dim = num_hiddens\n",
        "img_size = 96\n",
        "patch_size = 16\n",
        "num_blocks = 2\n",
        "\n",
        "n_layer, block_size, num_hiddens = 8, 32, 512\n",
        "\n",
        "# Initialize the model\n",
        "model = VisionLanguageModel(\n",
        "    n_embed=n_embed,\n",
        "    img_embed_dim=image_embed_dim,\n",
        "    vocab_size=vocab_size,\n",
        "    n_layer=n_layer,\n",
        "    img_size=img_size,\n",
        "    patch_size=patch_size,\n",
        "    num_heads=num_heads,\n",
        "    num_blocks=num_blocks,\n",
        "    emb_dropout=0.1,\n",
        "    block_dropout=0.1,\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "# Create dummy data with correct dimensions\n",
        "dummy_img = torch.randn(1, 3, img_size, img_size).to(\n",
        "    device\n",
        ")  # Correct shape for image input\n",
        "dummy_idx = torch.randint(0, vocab_size, (1, block_size)).to(\n",
        "    device\n",
        ")  # Correct shape for text input\n",
        "\n",
        "# Forward pass to initialize all parameters\n",
        "try:\n",
        "    output = model(dummy_img, dummy_idx)  # Output for debugging\n",
        "    print(\"Output from initialization forward pass:\", output)\n",
        "except RuntimeError as e:\n",
        "    print(f\"Runtime Error during forward pass: {str(e)}\")\n",
        "    print(\"Check layer configurations and input shapes.\")\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmwF7dW4Cf8Y",
        "outputId": "01a8476d-3ece-45c6-b9d1-2559d4923243"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Loss: 7.0728\n",
            "Model saved to my_model.pth\n"
          ]
        }
      ],
      "source": [
        "# TRAIN\n",
        "num_epochs = 1\n",
        "img_arrays = torch.randn(100, 3, img_size, img_size).to(\n",
        "    device\n",
        ")\n",
        "\n",
        "idxs = torch.randint(0, vocab_size, (100, block_size)).to(\n",
        "    device\n",
        ")\n",
        "\n",
        "targetss = torch.randint(0, vocab_size, (100, block_size)).to(\n",
        "    device\n",
        ")\n",
        "\n",
        "batch_size = 1\n",
        "num_batches = len(img_arrays) // batch_size\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        start = i * batch_size\n",
        "        end = start + batch_size\n",
        "\n",
        "        img_array = img_arrays[start:end]\n",
        "        idx = idxs[start:end]\n",
        "        targets = targetss[start:end]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits, loss = model(img_array, idx, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / num_batches\n",
        "    print(f\"Epoch {epoch+1} - Loss: {avg_loss:.4f}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"my_model.pth\")\n",
        "print(\"Model saved to my_model.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgA8TKfGGiW3"
      },
      "source": [
        "#1.2 base model vs ref_model load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "collapsed": true,
        "id": "ewM4KcCRebre"
      },
      "outputs": [],
      "source": [
        "n_embed, num_hiddens, num_heads, n_layer = 128, 512, 8, 8\n",
        "image_embed_dim = num_hiddens\n",
        "img_size = 96\n",
        "patch_size = 16\n",
        "num_blocks = 2\n",
        "\n",
        "n_layer, block_size, num_hiddens = 8, 32, 512\n",
        "\n",
        "# Initialize the model\n",
        "vlm = VisionLanguageModel(\n",
        "    n_embed=n_embed,\n",
        "    img_embed_dim=image_embed_dim,\n",
        "    vocab_size=tokenizer.vocab_size(),\n",
        "    n_layer=n_layer,\n",
        "    img_size=img_size,\n",
        "    patch_size=patch_size,\n",
        "    num_heads=num_heads,\n",
        "    num_blocks=num_blocks,\n",
        "    emb_dropout=0.1,\n",
        "    block_dropout=0.1,\n",
        ")\n",
        "device = torch.device('cpu')\n",
        "vlm.to(device)\n",
        "\n",
        "# Optimizer, chọn bộ phù hợp, chưa thử nhiều nên không bt bộ nào tốt\n",
        "# optimizer = torch.optim.AdamW(vlm.parameters(), lr=1e-4)\n",
        "optimizer = torch.optim.SGD(vlm.parameters(), lr=0.001, momentum=0.9)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "dPh0MYgfGm4v"
      },
      "outputs": [],
      "source": [
        "# Create DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "dataloader = DataLoader(dataset2, batch_size=8, shuffle=True, collate_fn=collate_fn2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t88hs3yakSww",
        "outputId": "cb7bdf37-ff00-4f76-b2e0-551a5af55432"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   0%|                                                                                                                               | 0/156 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (197) must match the size of tensor b (37) at non-singleton dimension 1",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m imgs = imgs.to(device)\n\u001b[32m     20\u001b[39m target_ids = target_ids.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m _, loss = \u001b[43mvlm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m loss = loss / accumulation_steps  \u001b[38;5;66;03m# Normalize the loss\u001b[39;00m\n\u001b[32m     24\u001b[39m loss.backward()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/train_vlm/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/train_vlm/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mVisionLanguageModel.forward\u001b[39m\u001b[34m(self, img_array, idx, targets)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m     54\u001b[39m     \u001b[38;5;28mself\u001b[39m, img_array: torch.Tensor, idx: torch.Tensor, targets: torch.Tensor = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     55\u001b[39m ) -> torch.Tensor | Tuple[torch.Tensor, torch.Tensor]:\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# Get the image embeddings from the Vision Encoder\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     image_embeds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvision_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m     \u001b[38;5;66;03m# Check if image embeddings are valid\u001b[39;00m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_image_embeddings(image_embeds)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/train_vlm/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/train_vlm/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mViT.forward\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     59\u001b[39m x = torch.cat(\n\u001b[32m     60\u001b[39m     tensors=(cls_tokens, x), dim=\u001b[32m1\u001b[39m\n\u001b[32m     61\u001b[39m )  \u001b[38;5;66;03m# Shape: (B, num_patches + 1, num_hiddens)\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Add the position embedding to the patch embeddings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpos_embedding\u001b[49m  \u001b[38;5;66;03m# Shape: (B, num_patches + 1, num_hiddens)\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Apply dropout to the embeddings\u001b[39;00m\n\u001b[32m     67\u001b[39m x = \u001b[38;5;28mself\u001b[39m.dropout(x)  \u001b[38;5;66;03m# Shape: (B, num_patches + 1, num_hiddens)\u001b[39;00m\n",
            "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (197) must match the size of tensor b (37) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "# ... (previous code) ...\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "# Use AdamW optimizer\n",
        "optimizer = torch.optim.AdamW(vlm.parameters(), lr=1e-4)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)  # Reduce LR by a factor of 0.1 every 3 epochs\n",
        "\n",
        "# Gradient accumulation\n",
        "accumulation_steps = 2\n",
        "\n",
        "vlm.train()\n",
        "for epoch in range(10):\n",
        "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch + 1}\")\n",
        "    total_loss = 0\n",
        "    for i, (imgs, input_ids, target_ids) in enumerate(pbar):\n",
        "        input_ids = input_ids.to(device)\n",
        "        imgs = imgs.to(device)\n",
        "        target_ids = target_ids.to(device)\n",
        "\n",
        "        _, loss = vlm(imgs, input_ids, targets=target_ids)\n",
        "        loss = loss / accumulation_steps  # Normalize the loss\n",
        "        loss.backward()\n",
        "\n",
        "        if (i + 1) % accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        pbar.set_postfix({\"loss\": loss.item()})\n",
        "\n",
        "    scheduler.step()  # Update learning rate\n",
        "\n",
        "    print(f\"Epoch {epoch+1} - Avg Loss: {total_loss / len(dataloader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xH6oc_sPUAmM",
        "outputId": "58de867c-a07d-4c94-d1be-4d3ffadf888b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(vlm.state_dict(), \"model_10.pth\")\n",
        "print(\"Model saved to model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zjBe1a_krzr"
      },
      "source": [
        "# 1.1 SFT base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "mDeARM_yPzfg"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for VisionLanguageModel:\n\tsize mismatch for decoder.token_embedding_table.weight: copying a param with shape torch.Size([1000, 128]) from checkpoint, the shape in current model is torch.Size([128000, 128]).\n\tsize mismatch for decoder.lm_head.weight: copying a param with shape torch.Size([1000, 128]) from checkpoint, the shape in current model is torch.Size([128000, 128]).\n\tsize mismatch for decoder.lm_head.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([128000]).",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      1\u001b[39m model = VisionLanguageModel(\n\u001b[32m      2\u001b[39m     n_embed=n_embed,\n\u001b[32m      3\u001b[39m     img_embed_dim=image_embed_dim,\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     block_dropout=\u001b[32m0.1\u001b[39m,\n\u001b[32m     12\u001b[39m )\n\u001b[32m     13\u001b[39m model.to(\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmy_model.pth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/train_vlm/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:2593\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2585\u001b[39m         error_msgs.insert(\n\u001b[32m   2586\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2587\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2588\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2589\u001b[39m             ),\n\u001b[32m   2590\u001b[39m         )\n\u001b[32m   2592\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2593\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2594\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2595\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2596\u001b[39m         )\n\u001b[32m   2597\u001b[39m     )\n\u001b[32m   2598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
            "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for VisionLanguageModel:\n\tsize mismatch for decoder.token_embedding_table.weight: copying a param with shape torch.Size([1000, 128]) from checkpoint, the shape in current model is torch.Size([128000, 128]).\n\tsize mismatch for decoder.lm_head.weight: copying a param with shape torch.Size([1000, 128]) from checkpoint, the shape in current model is torch.Size([128000, 128]).\n\tsize mismatch for decoder.lm_head.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([128000])."
          ]
        }
      ],
      "source": [
        "model = VisionLanguageModel(\n",
        "    n_embed=n_embed,\n",
        "    img_embed_dim=image_embed_dim,\n",
        "    vocab_size=tokenizer.vocab_size(),\n",
        "    n_layer=n_layer,\n",
        "    img_size=img_size,\n",
        "    patch_size=patch_size,\n",
        "    num_heads=num_heads,\n",
        "    num_blocks=num_blocks,\n",
        "    emb_dropout=0.1,\n",
        "    block_dropout=0.1,\n",
        ")\n",
        "model.to('cpu')\n",
        "model.load_state_dict(torch.load(\"my_model.pth\", map_location=torch.device('cpu')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQqT-tVKzxB5"
      },
      "outputs": [],
      "source": [
        "model.train()\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in dataloader:\n",
        "        inputs = {k: v.squeeze(1).to(device) for k, v in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        loss = loss_fn(outputs.logits.view(-1, vocab_size), inputs[\"labels\"].view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAwzXiOqAO1u"
      },
      "source": [
        "#2 Reward model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBS0s_KuTLK9"
      },
      "source": [
        "## Reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZJrvOnj9Hmq_",
        "outputId": "7abfbbf5-2c4a-4ce3-b9a0-c1a0922d5f3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'image': tensor([[[0.2196, 0.2353, 0.3569,  ..., 0.8588, 0.8549, 0.8471],\n",
              "          [0.2510, 0.3451, 0.4078,  ..., 0.8667, 0.8588, 0.8510],\n",
              "          [0.3725, 0.4353, 0.4353,  ..., 0.8706, 0.8627, 0.8549],\n",
              "          ...,\n",
              "          [0.5294, 0.5490, 0.5765,  ..., 0.6314, 0.6667, 0.6667],\n",
              "          [0.5490, 0.5765, 0.5882,  ..., 0.6196, 0.6353, 0.6392],\n",
              "          [0.5569, 0.5922, 0.5922,  ..., 0.6392, 0.6353, 0.6275]],\n",
              " \n",
              "         [[0.2353, 0.2353, 0.3490,  ..., 0.9922, 0.9922, 0.9882],\n",
              "          [0.2745, 0.3569, 0.4157,  ..., 0.9922, 0.9922, 0.9882],\n",
              "          [0.4118, 0.4706, 0.4745,  ..., 0.9961, 0.9922, 0.9922],\n",
              "          ...,\n",
              "          [0.1608, 0.1765, 0.2000,  ..., 0.5922, 0.6275, 0.6275],\n",
              "          [0.1725, 0.2000, 0.2039,  ..., 0.5804, 0.5961, 0.6000],\n",
              "          [0.1804, 0.2118, 0.2039,  ..., 0.6000, 0.5961, 0.5882]],\n",
              " \n",
              "         [[0.2510, 0.2627, 0.3882,  ..., 0.9961, 0.9922, 0.9882],\n",
              "          [0.3020, 0.3922, 0.4667,  ..., 0.9961, 0.9961, 0.9922],\n",
              "          [0.4510, 0.5137, 0.5373,  ..., 0.9961, 0.9922, 0.9882],\n",
              "          ...,\n",
              "          [0.3412, 0.3569, 0.3765,  ..., 0.5882, 0.6235, 0.6235],\n",
              "          [0.3529, 0.3765, 0.3765,  ..., 0.5765, 0.5922, 0.5961],\n",
              "          [0.3529, 0.3882, 0.3765,  ..., 0.5961, 0.5922, 0.5843]]]),\n",
              " 'chosen_input_ids': tensor([23376,   291,  1115,   267,  2353,   260,   279,  1115, 12232,   266,\n",
              "         45508,  2011,  1972,   399,   375,  1164,  2794,   281,  4289,  3258,\n",
              "          5395,   260,   443,   281, 19581,   277,   311,   626,   265,   262,\n",
              "          2011,   261, 13150,   262,  2794,   263,   262,  5395,   260,   589,\n",
              "           262,   340,   626,   265,   262,  2011,   261,  2217, 21668,   281,\n",
              "         11111,   261,  6050,   641,   262,  2363,   265,   262, 16932,   260,\n",
              "           279,  2192,   265,   462, 19581,   263,   262, 11111, 21668,  3788,\n",
              "           266,  2418,   263,  3685,  3384,   260,   279,  5713,  1164,  2794,\n",
              "           800,   266,  4671,  3036,   264,   262,  1972,   261, 17566,   390,\n",
              "           262, 45508,  1212,   880,   262,  2911,  2019,   260,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0]),\n",
              " 'reject_input_ids': tensor([23376,   291,  1115,   267,  2353,   260,   279,  1115, 12232,   266,\n",
              "         45508,  2011,  1972,   399,   375,  1164,  2794,   281,  4289,  3258,\n",
              "          5395,   260,   443,   281, 19581,   277,   311,   626,   265,   262,\n",
              "          2011,   261, 13150,   262,  2794,   263,   262,  5395,   260,   589,\n",
              "           262,   340,   626,   265,   262,  2011,   261,  2217, 21668,   281,\n",
              "         11111,   261,  6050,   641,   262,  2363,   265,   262, 16932,   260,\n",
              "           279,  2192,   265,   462, 19581,   263,   262, 11111, 21668,  3788,\n",
              "           266,  2418,   263,  3685,  3384,   260,   279,  5713,  1164,  2794,\n",
              "           800,   266,  4671,  3036,   264,   262,  1972,   261, 17566,   390,\n",
              "           262, 45508,  1212,   880,   262,  2911,  2019,   260,   344,   262,\n",
              "          2008,   261,   266,   792,   289, 34592,   295,   282,   757,   261,\n",
              "          2016,   264,   262,  3599, 21640,   265,   262,  1972,   260,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0])}"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "dataloader2 = DataLoader(dataset2, batch_size=4, shuffle=True, collate_fn=collate_fn2)\n",
        "dataset2[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "v6M0YIYr718L"
      },
      "outputs": [],
      "source": [
        "class DecoderLanguageModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_embed: int,\n",
        "        img_embed_dim: int,\n",
        "        vocab_size: int,\n",
        "        num_heads: int,\n",
        "        n_layer: int,\n",
        "        use_images: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.use_images = use_images\n",
        "\n",
        "        # Token embedding table\n",
        "        self.token_embedding_table = nn.Embedding(\n",
        "            num_embeddings=vocab_size, embedding_dim=n_embed\n",
        "        )\n",
        "\n",
        "        # Position embedding table\n",
        "        self.position_embedding_table = nn.Embedding(\n",
        "            num_embeddings=1000, embedding_dim=n_embed\n",
        "        )\n",
        "\n",
        "        if use_images:\n",
        "            # Image projection layer to align image embeddings with text embeddings\n",
        "            self.image_projection = MultiModalProjector(\n",
        "                n_embed=n_embed, img_embed_dim=img_embed_dim\n",
        "            )\n",
        "\n",
        "        # Stack of transformer decoder blocks\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[\n",
        "                Block(n_embed=n_embed, num_heads=num_heads, is_decoder=True)\n",
        "                for _ in range(n_layer)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Final layer normalization\n",
        "        self.ln_f = nn.LayerNorm(normalized_shape=n_embed)\n",
        "\n",
        "        # Language modeling head\n",
        "        self.lm_head = nn.Linear(in_features=n_embed, out_features=vocab_size)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        idx: torch.Tensor,\n",
        "        img_embeds: torch.Tensor = None,\n",
        "        targets: torch.Tensor = None,\n",
        "        return_hidden:bool = True,\n",
        "    ) -> torch.Tensor:\n",
        "        # Get token embeddings from the input indices\n",
        "        tok_emb = self.token_embedding_table(idx)\n",
        "\n",
        "        if self.use_images:\n",
        "            # Project and concatenate image embeddings with token embeddings\n",
        "            img_emb = self.image_projection(img_embeds).unsqueeze(1)\n",
        "            tok_emb = torch.cat([img_emb, tok_emb], dim=1)\n",
        "\n",
        "        # Get position embeddings\n",
        "        pos_emb = self.position_embedding_table(\n",
        "            torch.arange(tok_emb.size(1), device=idx.device)\n",
        "        )\n",
        "\n",
        "        # Add position embeddings to token embeddings\n",
        "        x = tok_emb + pos_emb\n",
        "\n",
        "        # Pass through the transformer decoder blocks\n",
        "        x = self.blocks(x)\n",
        "\n",
        "        # Apply final layer normalization\n",
        "        x = self.ln_f(x)\n",
        "        if return_hidden:\n",
        "            return x  # Return hidden state (B, T, D)\n",
        "        # Get the logits from the language modeling head\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is not None:\n",
        "            if self.use_images and img_embeds is not None:\n",
        "                # Prepare targets by concatenating a dummy target for the image embedding\n",
        "                batch_size = idx.size(0)\n",
        "                targets = torch.cat(\n",
        "                    [\n",
        "                        torch.full(\n",
        "                            (batch_size, 1), -100, dtype=torch.long, device=idx.device\n",
        "                        ),\n",
        "                        targets,\n",
        "                    ],\n",
        "                    dim=1,\n",
        "                )\n",
        "\n",
        "            # Compute the cross-entropy loss\n",
        "            loss = F.cross_entropy(\n",
        "                input=logits.view(-1, logits.size(-1)),\n",
        "                target=targets.view(-1),\n",
        "                ignore_index=-100,\n",
        "            )\n",
        "            return logits, loss\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def generate(\n",
        "        self, idx: torch.Tensor, img_embeds: torch.Tensor, max_new_tokens: int\n",
        "    ) -> torch.Tensor:\n",
        "        # Get the batch size and sequence length\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # Initialize the generated sequence with the input indices\n",
        "        generated = idx\n",
        "        tok_emb = self.token_embedding_table(idx)\n",
        "\n",
        "        if self.use_images and img_embeds is not None:\n",
        "            # Project and concatenate image embeddings with token embeddings\n",
        "            img_emb = self.image_projection(img_embeds).unsqueeze(1)\n",
        "            current_output = torch.cat([img_emb, tok_emb], dim=1)\n",
        "        else:\n",
        "            current_output = tok_emb\n",
        "\n",
        "        # Generate new tokens iteratevely\n",
        "        for i in range(max_new_tokens):\n",
        "            # Get the current sequence length\n",
        "            T_current = current_output.shape[1]\n",
        "\n",
        "            # Get position embeddings for the current sequence length\n",
        "            current_pos_emb = self.position_embedding_table(\n",
        "                torch.arange(T_current, device=idx.device)\n",
        "            ).unsqueeze(0)\n",
        "\n",
        "            # Add position embeddings to the current output\n",
        "            current_output += current_pos_emb\n",
        "\n",
        "            # Pass through the transformer decoder blocks\n",
        "            for block in self.blocks:\n",
        "                current_output = block(current_output)\n",
        "\n",
        "            # Get the logits for the last token\n",
        "            logits = self.lm_head(current_output[:, -1, :])\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "            # Sample the next token based on the probability\n",
        "            idx_next = torch.multinomial(input=probs, num_samples=1)\n",
        "\n",
        "            # Concatenate the generated token to the generated sequence\n",
        "            generated = torch.cat([generated, idx_next], dim=1)\n",
        "\n",
        "            # Get the embeddings for the generated token\n",
        "            idx_next_emb = self.token_embedding_table(idx_next)\n",
        "\n",
        "            # Concatenate the generated token embeddings to the current output\n",
        "            current_output = torch.cat([current_output, idx_next_emb], dim=1)\n",
        "\n",
        "        return generated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "wslKc9lAIVK-"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RewardModel(nn.Module):\n",
        "    def __init__(self, vlm: VisionLanguageModel, hidden_dim: int = 768):\n",
        "        super().__init__()\n",
        "        self.vlm = vlm\n",
        "\n",
        "        # You can modify this head (e.g., deeper MLP) if needed\n",
        "        self.reward_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 1)\n",
        "        )\n",
        "    def forward(self, img_array: torch.Tensor, input_ids: torch.Tensor) -> torch.Tensor:\n",
        "        # Encode image using ViT\n",
        "        image_embeds = self.vlm.vision_encoder(img_array)\n",
        "\n",
        "        # Get hidden states from decoder\n",
        "        hidden_states = self.vlm.decoder(\n",
        "            idx=input_ids,\n",
        "            img_embeds=image_embeds,\n",
        "            return_hidden=True  # This is the key addition\n",
        "        )  # (B, T+1, D) — if image embed is prepended\n",
        "\n",
        "        # Option 1: Use image token (first token after img_embeds)\n",
        "        pooled = hidden_states[:, 0, :]  # (B, D)\n",
        "\n",
        "        # Option 2: Use last token — hidden_states[:, -1, :]\n",
        "        # Option 3: Mean pooling — hidden_states.mean(dim=1)\n",
        "\n",
        "        reward = self.reward_head(pooled).squeeze(-1)  # (B,)\n",
        "        return reward\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ke2Xxzb_ZvT",
        "outputId": "15ce7454-a958-4796-bb9f-a6ba341d03b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "torch.Size([4, 64])\n",
            "Rewards: tensor([0.1923, 0.0498, 0.1760, 0.1713], grad_fn=<SqueezeBackward1>)\n"
          ]
        }
      ],
      "source": [
        "# Instantiate base VLM\n",
        "vlm = VisionLanguageModel(\n",
        "    n_embed=768,\n",
        "    img_embed_dim=768,\n",
        "    vocab_size=30522,\n",
        "    n_layer=6,\n",
        "    img_size=224,\n",
        "    patch_size=16,\n",
        "    num_heads=12,\n",
        "    num_blocks=6,\n",
        "    emb_dropout=0.1,\n",
        "    block_dropout=0.1\n",
        ").to(device)\n",
        "\n",
        "# Wrap in RewardModel\n",
        "reward_model = RewardModel(vlm=vlm, hidden_dim=768).to(device)\n",
        "\n",
        "# Example input\n",
        "img_tensor = torch.randn(4, 3, 224, 224).to(device)      # batch of 2 images\n",
        "text_input = torch.randint(0, 30522, (4, 64)).to(device)  # batch of 2 text sequences\n",
        "\n",
        "# Forward pass to get reward values\n",
        "rewards = reward_model(img_tensor, text_input)\n",
        "print(img_tensor.shape)\n",
        "print(text_input.shape)\n",
        "print(\"Rewards:\", rewards)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "fw_-q_73mKSk"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "t = torch.tensor([1,2], device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   0%|                                                                              | 0/311 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "torch.Size([4, 256])\n",
            "torch.Size([4, 256])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   0%|▏                                                                     | 1/311 [00:02<13:55,  2.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "torch.Size([4, 256])\n",
            "torch.Size([4, 256])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   1%|▍                                                                     | 2/311 [00:05<13:10,  2.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "torch.Size([4, 256])\n",
            "torch.Size([4, 256])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   1%|▍                                                                     | 2/311 [00:07<18:19,  3.56s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(rejected_ids.shape)\n\u001b[32m     28\u001b[39m r_chosen = reward_model(imgs, chosen_ids)  \u001b[38;5;66;03m# (B,) [B] [B,C, H,W]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m r_rejected = \u001b[43mreward_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrejected_ids\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B,)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/train_vlm/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/train_vlm/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[84]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mRewardModel.forward\u001b[39m\u001b[34m(self, img_array, input_ids)\u001b[39m\n\u001b[32m     16\u001b[39m image_embeds = \u001b[38;5;28mself\u001b[39m.vlm.vision_encoder(img_array)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Get hidden states from decoder\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvlm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimg_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_hidden\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# This is the key addition\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B, T+1, D) — if image embed is prepended\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Option 1: Use image token (first token after img_embeds)\u001b[39;00m\n\u001b[32m     26\u001b[39m pooled = hidden_states[:, \u001b[32m0\u001b[39m, :]  \u001b[38;5;66;03m# (B, D)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/train_vlm/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/train_vlm/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 69\u001b[39m, in \u001b[36mDecoderLanguageModel.forward\u001b[39m\u001b[34m(self, idx, img_embeds, targets, return_hidden)\u001b[39m\n\u001b[32m     66\u001b[39m x = tok_emb + pos_emb\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Pass through the transformer decoder blocks\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# Apply final layer normalization\u001b[39;00m\n\u001b[32m     72\u001b[39m x = \u001b[38;5;28mself\u001b[39m.ln_f(x)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/train_vlm/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/train_vlm/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/train_vlm/.env/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/train_vlm/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/train_vlm/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     45\u001b[39m x = \u001b[38;5;28mself\u001b[39m.ln2(x)\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Apply the FFN\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m ffn_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mffn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Apply the residual connection (input to the FFN) to the FFN output\u001b[39;00m\n\u001b[32m     51\u001b[39m x = x + ffn_output\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/train_vlm/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/train_vlm/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/train_vlm/.env/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/train_vlm/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/train_vlm/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/train_vlm/.env/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Instantiate base VLM\n",
        "vlm = VisionLanguageModel(\n",
        "    n_embed=768,\n",
        "    img_embed_dim=768,\n",
        "    vocab_size=tokenizer.vocab_size(),\n",
        "    n_layer=6,\n",
        "    img_size=224,\n",
        "    patch_size=16,\n",
        "    num_heads=12,\n",
        "    num_blocks=6,\n",
        "    emb_dropout=0.1,\n",
        "    block_dropout=0.1\n",
        ").to(device)\n",
        "\n",
        "# Wrap in RewardModel\n",
        "reward_model = RewardModel(vlm=vlm, hidden_dim=768).to(device)\n",
        "\n",
        "for epoch in range(1):\n",
        "        pbar = tqdm(dataloader2, desc=f\"Epoch {epoch + 1}\")\n",
        "        total_loss = 0\n",
        "        for i, (imgs, chosen_ids, rejected_ids) in enumerate(pbar):\n",
        "            imgs = imgs.to(device)\n",
        "            chosen_ids = chosen_ids.to(device)\n",
        "            rejected_ids = rejected_ids.to(device)\n",
        "            print(imgs.shape)\n",
        "            print(chosen_ids.shape)\n",
        "            print(rejected_ids.shape)\n",
        "            r_chosen = reward_model(imgs, chosen_ids)  # (B,) [B] [B,C, H,W]\n",
        "            r_rejected = reward_model(imgs, rejected_ids)  # (B,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "vluqFCtDAkFj",
        "outputId": "ad04af80-7727-4068-c1b1-2ceb062879a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|████████████████████████████████████████████████████████████████████| 311/311 [23:47<00:00,  4.59s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Loss: 1.3983\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|████████████████████████████████████████████████████████████████████| 311/311 [23:09<00:00,  4.47s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Loss: 1.3886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|████████████████████████████████████████████████████████████████████| 311/311 [23:11<00:00,  4.47s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Loss: 1.3842\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|████████████████████████████████████████████████████████████████████| 311/311 [23:15<00:00,  4.49s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Loss: 1.3869\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████████████████████████████████████████████████████████████| 311/311 [1:00:25<00:00, 11.66s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Loss: 1.3867\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6:  40%|██████████████████████████▎                                       | 124/311 [47:57<1:13:16, 23.51s/it]"
          ]
        }
      ],
      "source": [
        "from torch.nn.functional import sigmoid\n",
        "from torch.optim import AdamW\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "def train_reward_model(reward_model, df, epochs=10, batch_size=4, lr=1e-5, tokenizer=None):\n",
        "    optimizer = AdamW(reward_model.parameters(), lr=lr)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    reward_model.to(device)\n",
        "    reward_model.train()\n",
        "    for epoch in range(epochs):\n",
        "        pbar = tqdm(df, desc=f\"Epoch {epoch + 1}\")\n",
        "        total_loss = 0\n",
        "        for i, (imgs, chosen_ids, rejected_ids) in enumerate(pbar):\n",
        "            imgs = imgs.to(device)\n",
        "            chosen_ids = chosen_ids.to(device)\n",
        "            rejected_ids = rejected_ids.to(device)\n",
        "            # print(imgs.shape)\n",
        "            # print(chosen_ids.shape)\n",
        "            # print(rejected_ids.shape)\n",
        "            r_chosen = reward_model(imgs, chosen_ids)  # (B,) [B] [B,C, H,W]\n",
        "            r_rejected = reward_model(imgs, rejected_ids)  # (B,)\n",
        "\n",
        "            # Pairwise ranking loss\n",
        "            loss = -torch.log(sigmoid(r_chosen - r_rejected)).mean()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss / len(dataloader):.4f}\")\n",
        "vlm = VisionLanguageModel(\n",
        "    n_embed=768,\n",
        "    img_embed_dim=768,\n",
        "    vocab_size=tokenizer.vocab_size(),\n",
        "    n_layer=6,\n",
        "    img_size=224,\n",
        "    patch_size=16,\n",
        "    num_heads=12,\n",
        "    num_blocks=6,\n",
        "    emb_dropout=0.1,\n",
        "    block_dropout=0.1\n",
        ").to(device)\n",
        "reward_model = RewardModel(vlm=vlm, hidden_dim=768).to(device)\n",
        "train_reward_model(reward_model, dataloader2 , epochs=10, batch_size=4, lr=1e-5, tokenizer = tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ3spGLcBYS9"
      },
      "source": [
        "# 3 PPO model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdTj8LRJJ7YQ"
      },
      "source": [
        "## Gen cap with log prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14GLOrjNENAI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def generate_caption_with_log_probs(vlm_model, tokenizer, image_tensor, prompt_ids, max_length=20):\n",
        "    \"\"\"\n",
        "    Sinh caption từ VLM + tính log-prob từng token (dùng trong PPO)\n",
        "\n",
        "    Args:\n",
        "        vlm_model: Vision-Language model\n",
        "        tokenizer: Tokenizer dùng để encode/decode\n",
        "        image_tensor: Tensor ảnh, shape (B, C, H, W)\n",
        "        prompt_ids: Tensor (B, T), token ids của prompt\n",
        "        max_length: Độ dài caption tối đa\n",
        "\n",
        "    Returns:\n",
        "        output_ids: (B, max_len), ids caption được sinh\n",
        "        log_probs: (B, max_len), log-prob từng token\n",
        "    \"\"\"\n",
        "    device = image_tensor.device\n",
        "    B = image_tensor.size(0)\n",
        "    output_ids = []\n",
        "    log_probs = []\n",
        "\n",
        "    input_ids = prompt_ids.clone()\n",
        "    # ....... fix lai\n",
        "    for _ in range(max_length):\n",
        "        logits = vlm_model(image_tensor, input_ids)  # (B, T, V)\n",
        "        next_token_logits = logits[:, -1, :]  # (B, V)\n",
        "\n",
        "        probs = F.softmax(next_token_logits, dim=-1)\n",
        "        log_prob = F.log_softmax(next_token_logits, dim=-1)\n",
        "\n",
        "        # Sampling (để PPO có đa dạng response)\n",
        "        next_tokens = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "\n",
        "        # Lưu log-probs theo token đã chọn\n",
        "        selected_log_probs = log_prob.gather(1, next_tokens)  # (B, 1)\n",
        "\n",
        "        # Append kết quả\n",
        "        output_ids.append(next_tokens)\n",
        "        log_probs.append(selected_log_probs)\n",
        "\n",
        "        # Update input\n",
        "        input_ids = torch.cat([input_ids, next_tokens], dim=1)\n",
        "\n",
        "    # Kết quả dạng (B, max_len)\n",
        "    output_ids = torch.cat(output_ids, dim=1)\n",
        "    log_probs = torch.cat(log_probs, dim=1)\n",
        "\n",
        "    return output_ids, log_probs\n",
        "# Example:\n",
        "# # Dữ liệu input\n",
        "# image_tensor = encode_image(image).unsqueeze(0).to(device)\n",
        "# prompt_ids = tokenizer(\"A photo of\", return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "# # Sinh caption + log_probs\n",
        "# caption_ids, log_probs = generate_caption_with_log_probs(vlm_model, tokenizer, image_tensor, prompt_ids)\n",
        "\n",
        "# # Decode caption\n",
        "# caption_text = tokenizer.decode(caption_ids[0], skip_special_tokens=True)\n",
        "# print(\"Caption:\", caption_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N98XTXiKCGS"
      },
      "source": [
        "## Compute loss ppo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAc2ejOiKKFd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def compute_ppo_loss(old_log_probs, new_log_probs, rewards, clip_epsilon=0.2):\n",
        "    \"\"\"\n",
        "    Tính PPO loss cho policy model\n",
        "\n",
        "    Args:\n",
        "        old_log_probs: (B, T) log-probs từ policy cũ\n",
        "        new_log_probs: (B, T) log-probs từ policy mới\n",
        "        rewards: (B,) reward scalar cho từng sample\n",
        "        clip_epsilon: hệ số clip (PPO)\n",
        "\n",
        "    Returns:\n",
        "        loss: scalar PPO loss\n",
        "    \"\"\"\n",
        "    # Chuyển rewards từ (B,) thành (B, T) để match với log_probs\n",
        "    rewards = rewards.unsqueeze(1).expand_as(old_log_probs)  # (B, T)\n",
        "\n",
        "    # Tính ratio\n",
        "    ratio = torch.exp(new_log_probs - old_log_probs)  # (B, T)\n",
        "\n",
        "    # Tính advantage = reward (không có value baseline)\n",
        "    advantage = rewards\n",
        "\n",
        "    # PPO loss (clipped)\n",
        "    unclipped = ratio * advantage\n",
        "    clipped = torch.clamp(ratio, 1 - clip_epsilon, 1 + clip_epsilon) * advantage\n",
        "    loss = -torch.min(unclipped, clipped).mean()\n",
        "\n",
        "    return loss\n",
        "#Example:\n",
        "# loss = compute_ppo_loss(old_log_probs, new_log_probs, rewards)\n",
        "# loss.backward()\n",
        "# optimizer.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x-WCB1iKn6Q"
      },
      "source": [
        "## ppo update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leCQRmykKsYA"
      },
      "outputs": [],
      "source": [
        "def ppo_update(policy_model, tokenizer, optimizer, reward_model, images, prompts, clip_epsilon=0.2, max_length=20):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        policy_model: mô hình VLM\n",
        "        tokenizer: tokenizer của model\n",
        "        optimizer: optimizer cho policy\n",
        "        reward_model: mô hình reward đã huấn luyện\n",
        "        images: (B, C, H, W)\n",
        "        prompts: list[str]\n",
        "        clip_epsilon: hệ số PPO clip\n",
        "        max_length: độ dài caption tối đa\n",
        "\n",
        "    Returns:\n",
        "        loss: giá trị loss PPO sau 1 bước update\n",
        "    \"\"\"\n",
        "    policy_model.train()\n",
        "\n",
        "    # Encode prompt\n",
        "    prompt_ids = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True).input_ids.to(images.device)\n",
        "\n",
        "    # === STEP 1: Generate captions with old policy ===\n",
        "    with torch.no_grad():\n",
        "        old_output_ids, old_log_probs = generate_caption_with_log_probs(\n",
        "            policy_model, tokenizer, images, prompt_ids, max_length=max_length\n",
        "        )\n",
        "\n",
        "    # === STEP 2: Compute reward for each (image, prompt, caption) ===\n",
        "    rewards = []\n",
        "    for i in range(len(images)):\n",
        "        prompt = prompts[i]\n",
        "        caption = tokenizer.decode(old_output_ids[i], skip_special_tokens=True)\n",
        "        reward = reward_model(images[i].unsqueeze(0), prompt, caption)  # scalar\n",
        "        rewards.append(reward)\n",
        "    rewards = torch.tensor(rewards).to(images.device)\n",
        "# ????? chỗ này chưa update model nên chưa có old-new !\n",
        "    # === STEP 3: Re-run policy to get new_log_probs ===\n",
        "    new_output_ids, new_log_probs = generate_caption_with_log_probs(\n",
        "        policy_model, tokenizer, images, prompt_ids, max_length=max_length\n",
        "    )\n",
        "\n",
        "    # === STEP 4: Compute PPO loss ===\n",
        "    loss = compute_ppo_loss(\n",
        "        old_log_probs=old_log_probs,\n",
        "        new_log_probs=new_log_probs,\n",
        "        rewards=rewards,\n",
        "        clip_epsilon=clip_epsilon\n",
        "    )\n",
        "\n",
        "    # === STEP 5: Update ===\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "# Example\n",
        "# loss = ppo_update(\n",
        "#     policy_model=vlm_model,\n",
        "#     tokenizer=vlm_tokenizer,\n",
        "#     optimizer=vlm_optimizer,\n",
        "#     reward_model=reward_model_fn,\n",
        "#     images=image_batch,\n",
        "#     prompts=[\"A photo of\", \"A scene of\"],\n",
        "#     clip_epsilon=0.2\n",
        "# )\n",
        "# print(\"PPO loss:\", loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd9VQiozJbF4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "022c4fee13bc4b7ca44d3ad002349538": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "065bd21725344fb1b8b26183eefcf0a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "067bd9b8b10c43b99a22b0495002a211": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0681076936ff4cd28c4825565b6550bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23903ec053d84dcb8e86de4155e3464f",
            "max": 2513,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f70aa8671464810a181ca1e42ff5a92",
            "value": 2513
          }
        },
        "07bada43d40f48c59ddda3c6068a358a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08699a3acf88491c9519838e5c12d060": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "090dd2df8a4942a282966131431e3e16": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09d706af97994df1bc5df673f92e5318": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_201b17047c4a45ecba7b304c82babef2",
              "IPY_MODEL_0df5235c28d74976b22062694b5e8a5c",
              "IPY_MODEL_5b9e4a31776b48cebab49047e6ea2c32"
            ],
            "layout": "IPY_MODEL_46cf6b35920e4118820539d9683d3ca9"
          }
        },
        "0bddc60a65e04b1a898461ecf6155483": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0df5235c28d74976b22062694b5e8a5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b878b9187713438baa67ee369e36f26e",
            "max": 31014,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fde4495c4c64956a382a2a2d16c7101",
            "value": 31014
          }
        },
        "0e3571256867403891eab79267038e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6485915b5d48433285b62cc1c19ad815",
            "placeholder": "​",
            "style": "IPY_MODEL_aeb67b7b85184d06bbd5333890ac2057",
            "value": "0003.parquet: 100%"
          }
        },
        "0ea440359b1b42d190445de68d0b34b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f002a5869e64ab4b73372ff050e13f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_217b5568e7f94e8cad96a0235a655589",
            "max": 496924754,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18d846b7502d4b9facb871ce25070f46",
            "value": 496924754
          }
        },
        "0f7a37d6a8794c2db22433f847834c63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10975ef82a52465386a63230668c33b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11078b8185bb4c7c98ec0ba7a6b7af97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "113bc7413aec4e1db4ec9248dccd68ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "123cd44f334c4aada4080d5867b090c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13886f8a25a6497b83cd09ce4d0b9393": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22403e8813c4475984638ebe7ddf7be4",
              "IPY_MODEL_0f002a5869e64ab4b73372ff050e13f0",
              "IPY_MODEL_3ae3affdc58747909d90e83bca1c06dc"
            ],
            "layout": "IPY_MODEL_e3a68d96b0594f9cbdb117011091f1aa"
          }
        },
        "16d18acc4d0f4f5e8093364afe68b7f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b66026dd389e4994a3b151ea42c7a7ca",
            "placeholder": "​",
            "style": "IPY_MODEL_95457140a3f5413e9ddd685f98833978",
            "value": "Generating test split: 100%"
          }
        },
        "16f3392d361f43e8a62dfe57ece6164d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "174ffde8c3b6469db8cef1f89c5616f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdd67c725d3543f3a83926496d5e29f9",
            "placeholder": "​",
            "style": "IPY_MODEL_c0d3795ca6554386a1798136403f6e23",
            "value": "test-00000-of-00001.parquet: 100%"
          }
        },
        "175e1766afb242d185148f1b6b59baad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41265df4285a43c6a8f7b3de83247b2c",
            "placeholder": "​",
            "style": "IPY_MODEL_20effb31ac2a4e2b9fe140716ee62e16",
            "value": "0006.parquet: 100%"
          }
        },
        "17d7b0acb8d34404b355f997bb536bde": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18d846b7502d4b9facb871ce25070f46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f94bd4cae7c452b91574b8db8d82a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e31f661a649d4b4e80196c9f22774beb",
              "IPY_MODEL_2be956718c8d49e386d4913df583937a",
              "IPY_MODEL_a6f6cc96a0b442b98189a04ced0a164f"
            ],
            "layout": "IPY_MODEL_de212cb8bb114212b0d3ebbb7df08f39"
          }
        },
        "201b17047c4a45ecba7b304c82babef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_698ff1f2d2694ef88ee90c94c3bb3cb0",
            "placeholder": "​",
            "style": "IPY_MODEL_643000272c344a79be6c8f8ff0b775a7",
            "value": "Generating test split: 100%"
          }
        },
        "20effb31ac2a4e2b9fe140716ee62e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "217b5568e7f94e8cad96a0235a655589": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22403e8813c4475984638ebe7ddf7be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f67440eef6dc4eceab0c2b5d72f0f0c4",
            "placeholder": "​",
            "style": "IPY_MODEL_8ae74ebe452b4978aa9cf0fc0292344c",
            "value": "0007.parquet: 100%"
          }
        },
        "234d3434f0ae4f70878ccdeb6883e104": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_341cb4e1d4d049daa7f7a9e1b6c232df",
              "IPY_MODEL_0681076936ff4cd28c4825565b6550bc",
              "IPY_MODEL_434b6efe46264f9d81c8cef838ee8334"
            ],
            "layout": "IPY_MODEL_17d7b0acb8d34404b355f997bb536bde"
          }
        },
        "23903ec053d84dcb8e86de4155e3464f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "246eee9f172c40d69123d295d01d7ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25f6c755e0c34b3c82fbd61722cdc7af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a680db2e803404abd3173bb091eef06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0637224629c41a1b4d2895900387bb1",
              "IPY_MODEL_4381c807d3f6454a90a5de10c674ce01",
              "IPY_MODEL_5a86bc8597e14c3c8f3022d808ba86fe"
            ],
            "layout": "IPY_MODEL_b86b6951532c482ca779bccbeca6f1fd"
          }
        },
        "2be956718c8d49e386d4913df583937a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e23406134bfb4d60b158d01e112519c4",
            "max": 641,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69c965d359574a2f94a4e25a97ff4c10",
            "value": 641
          }
        },
        "2c78047dd5b74558953fa36993b3c179": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dd9362ff0b8406785180655c753bceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f994cffd0c44b3397eddb8d387a5999": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_174ffde8c3b6469db8cef1f89c5616f4",
              "IPY_MODEL_47eb59e0f83e4aa982b95005a0283682",
              "IPY_MODEL_c1f405116e244128ba592fd13fedc605"
            ],
            "layout": "IPY_MODEL_c1e9631acf9b4563924da55fbc5a8b28"
          }
        },
        "307d8551854744ff8f616c97a978d9b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "339891c332be4cec95d759493f57a4c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3872b073448046c5a31e54bbe15b64fe",
            "max": 289359289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61e027b52e564caebcaacb0d43448c10",
            "value": 289359289
          }
        },
        "341cb4e1d4d049daa7f7a9e1b6c232df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_065bd21725344fb1b8b26183eefcf0a2",
            "placeholder": "​",
            "style": "IPY_MODEL_16f3392d361f43e8a62dfe57ece6164d",
            "value": "flickr30k.py: 100%"
          }
        },
        "37ffc1c73650480882ebb55918a98837": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f505bdd8f7843bbbebd7054a61cfe18",
            "placeholder": "​",
            "style": "IPY_MODEL_9d99727d6b594c15a997ba234e38230e",
            "value": " 512M/512M [00:02&lt;00:00, 289MB/s]"
          }
        },
        "3872b073448046c5a31e54bbe15b64fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ae3affdc58747909d90e83bca1c06dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ada6a0b7912f402b909e7d49bfbf2365",
            "placeholder": "​",
            "style": "IPY_MODEL_e8cbb6f8f71a496f9db0f8c8860286af",
            "value": " 497M/497M [00:01&lt;00:00, 297MB/s]"
          }
        },
        "3b9246ddf540486297d100388d92824c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_175e1766afb242d185148f1b6b59baad",
              "IPY_MODEL_99156a7ab6a4484a965a4d9b16bc88d8",
              "IPY_MODEL_e4ddc8062d6d4a0794dac8e97f9b4803"
            ],
            "layout": "IPY_MODEL_afc26dd748d24be4a1ec49fb303ddc00"
          }
        },
        "3d83e81f8923486eaba0b6f8ace3d96d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e474a03fa804ecda3129c1391b9c665": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d42de8800e9b41a58364f1abda3010ad",
            "placeholder": "​",
            "style": "IPY_MODEL_25f6c755e0c34b3c82fbd61722cdc7af",
            "value": "0005.parquet: 100%"
          }
        },
        "3efc8a8a198c4100aca4a7e43e72c0e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ecf1ea95e4ba481a8766f2a17ae53852",
              "IPY_MODEL_60dae6c3b2fe4de6b20ed19c40523050",
              "IPY_MODEL_477ab5d4052e43358c0dbb5564c51c91"
            ],
            "layout": "IPY_MODEL_022c4fee13bc4b7ca44d3ad002349538"
          }
        },
        "3f70aa8671464810a181ca1e42ff5a92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fde4495c4c64956a382a2a2d16c7101": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41265df4285a43c6a8f7b3de83247b2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42ca68dda6704c808b84b0bef2e4f6d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "434b6efe46264f9d81c8cef838ee8334": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f7a37d6a8794c2db22433f847834c63",
            "placeholder": "​",
            "style": "IPY_MODEL_a5ef40dfc1324723a4dac510e5bd4265",
            "value": " 2.51k/2.51k [00:00&lt;00:00, 154kB/s]"
          }
        },
        "4381c807d3f6454a90a5de10c674ce01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e7795a32fc14c52a552cba3c4a54f76",
            "max": 505834156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f05fded6f55e4dbc9dc4cf4690904684",
            "value": 505834156
          }
        },
        "44f02e4928de4ae4a9aeda65df6e753a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45969fbc49894771a298be8190821914": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42ca68dda6704c808b84b0bef2e4f6d8",
            "max": 495305542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a52a450a9ec044c794c998ab1b531033",
            "value": 495305542
          }
        },
        "46cf6b35920e4118820539d9683d3ca9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "477ab5d4052e43358c0dbb5564c51c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0fd101ec4824a50ad26c1c3f899b216",
            "placeholder": "​",
            "style": "IPY_MODEL_10975ef82a52465386a63230668c33b7",
            "value": " 502M/502M [00:04&lt;00:00, 143MB/s]"
          }
        },
        "47eb59e0f83e4aa982b95005a0283682": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_090dd2df8a4942a282966131431e3e16",
            "max": 96277171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55a043b5e11d46218adbd0ba4f929574",
            "value": 96277171
          }
        },
        "4b2661cf17d44ccbb7a03003c782c87f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f4acdaaf4bb4fb3a912cd315370c10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "542abbdafed54d5983937529f8e88b78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "557ff2778e90430cac290b98631b75d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55a043b5e11d46218adbd0ba4f929574": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58158ff326744386be8763d6fb19bd68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16d18acc4d0f4f5e8093364afe68b7f1",
              "IPY_MODEL_c923b45bcf624511b33150cf433088a9",
              "IPY_MODEL_f9bb9f950a08461bb80960116bf9a994"
            ],
            "layout": "IPY_MODEL_4b2661cf17d44ccbb7a03003c782c87f"
          }
        },
        "58aea6ef25ec4fa0801cf391d853f810": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59249e0fc70443b6b31c59b0f2f60a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a86bc8597e14c3c8f3022d808ba86fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc2617cba8904280963986b43184cfec",
            "placeholder": "​",
            "style": "IPY_MODEL_0bddc60a65e04b1a898461ecf6155483",
            "value": " 506M/506M [00:03&lt;00:00, 204MB/s]"
          }
        },
        "5b9e4a31776b48cebab49047e6ea2c32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff964d64bb77429da3dec0c8f140e025",
            "placeholder": "​",
            "style": "IPY_MODEL_59249e0fc70443b6b31c59b0f2f60a63",
            "value": " 31014/31014 [00:46&lt;00:00, 560.46 examples/s]"
          }
        },
        "5ec351887a5f407294a18b69df02de98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fbae8f490e84573833641f59d103d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8d452526fd641eda93d51280dee8601",
            "placeholder": "​",
            "style": "IPY_MODEL_9fff8cca28c647e0ab4738c50590b625",
            "value": " 495M/495M [00:01&lt;00:00, 286MB/s]"
          }
        },
        "60dae6c3b2fe4de6b20ed19c40523050": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f4e10125cbe41f38e4ea69b0fc9c446",
            "max": 501896374,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f41c5d99d8b48328625154ae305db61",
            "value": 501896374
          }
        },
        "61b42c4af0854535a5488f60c87e7e81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61e027b52e564caebcaacb0d43448c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "641e84de1f1e41439193ba6661d258dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "643000272c344a79be6c8f8ff0b775a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6485915b5d48433285b62cc1c19ad815": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68e79979ba5845898ef147d1d3087c77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "698ff1f2d2694ef88ee90c94c3bb3cb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69c965d359574a2f94a4e25a97ff4c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69ea5b27c03849dca4b0b08bf91817e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b497aed398349859b27564fb9fb8387": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d40172a7a9047a085252019f62986be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e026a886ded141dcbd5af167beb354ce",
            "placeholder": "​",
            "style": "IPY_MODEL_246eee9f172c40d69123d295d01d7ee6",
            "value": " 289M/289M [00:03&lt;00:00, 41.9MB/s]"
          }
        },
        "6f41c5d99d8b48328625154ae305db61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75389003220547d59674c84adc04ae9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1a4ec72204145169b39bf265a8f3ff3",
            "placeholder": "​",
            "style": "IPY_MODEL_9b3b6beaecfa4c88b4d7c14eed0fb4f6",
            "value": " 2.97k/2.97k [00:00&lt;00:00, 68.6kB/s]"
          }
        },
        "761952237a8e4cf7ada1b65d6e88853a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e7795a32fc14c52a552cba3c4a54f76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8428cafea30c4acd995553d65f4e3770": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85dffbb4d9a14d3c8f9e907553596252": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69ea5b27c03849dca4b0b08bf91817e7",
            "max": 505667437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be622481a5de458eb919b2ef7b0471fe",
            "value": 505667437
          }
        },
        "8ae74ebe452b4978aa9cf0fc0292344c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95457140a3f5413e9ddd685f98833978": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96874952db58467e9967c5a4c92c39f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7dc61325d7949bfbe2451d5ded4ed59",
            "max": 503648349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4aabc12b3684fb69f37cabb28d0fd89",
            "value": 503648349
          }
        },
        "97aad66242094b76bbc1c9af0777a11f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a742223ef1a54a54bf65981b3301ddc7",
            "max": 2974,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58aea6ef25ec4fa0801cf391d853f810",
            "value": 2974
          }
        },
        "99156a7ab6a4484a965a4d9b16bc88d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44f02e4928de4ae4a9aeda65df6e753a",
            "max": 495475995,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_123cd44f334c4aada4080d5867b090c4",
            "value": 495475995
          }
        },
        "9a55b9689e5a45f1b8015f6ead02af1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b3b6beaecfa4c88b4d7c14eed0fb4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d99727d6b594c15a997ba234e38230e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f4e10125cbe41f38e4ea69b0fc9c446": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f505bdd8f7843bbbebd7054a61cfe18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fff8cca28c647e0ab4738c50590b625": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0637224629c41a1b4d2895900387bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee275536a6b4441bb6e934cdf72b564a",
            "placeholder": "​",
            "style": "IPY_MODEL_641e84de1f1e41439193ba6661d258dd",
            "value": "0002.parquet: 100%"
          }
        },
        "a52a450a9ec044c794c998ab1b531033": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5a36d741cea4450813aee66f42811b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b97bb17615f049a8a91e128d6048caa6",
              "IPY_MODEL_97aad66242094b76bbc1c9af0777a11f",
              "IPY_MODEL_75389003220547d59674c84adc04ae9a"
            ],
            "layout": "IPY_MODEL_08699a3acf88491c9519838e5c12d060"
          }
        },
        "a5ef40dfc1324723a4dac510e5bd4265": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6f6cc96a0b442b98189a04ced0a164f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d12e7fd4fcff4275bea3575a285eedf9",
            "placeholder": "​",
            "style": "IPY_MODEL_e06613869dff468aa5c33c5fcf77bc74",
            "value": " 641/641 [00:00&lt;00:00, 11.1kB/s]"
          }
        },
        "a742223ef1a54a54bf65981b3301ddc7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab6268ffda714aa487859104694a6bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db66ad84f6e746db8f81f6b01f168cdd",
              "IPY_MODEL_339891c332be4cec95d759493f57a4c7",
              "IPY_MODEL_6d40172a7a9047a085252019f62986be"
            ],
            "layout": "IPY_MODEL_8428cafea30c4acd995553d65f4e3770"
          }
        },
        "ada6a0b7912f402b909e7d49bfbf2365": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeb67b7b85184d06bbd5333890ac2057": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aec0a19bb5d441dcb7f8e529f13513b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e474a03fa804ecda3129c1391b9c665",
              "IPY_MODEL_45969fbc49894771a298be8190821914",
              "IPY_MODEL_5fbae8f490e84573833641f59d103d13"
            ],
            "layout": "IPY_MODEL_067bd9b8b10c43b99a22b0495002a211"
          }
        },
        "afc26dd748d24be4a1ec49fb303ddc00": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b164df86fc3a46e08ef36691e276ca65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef1f8e91f41447318865eb2618bdd81a",
            "placeholder": "​",
            "style": "IPY_MODEL_ca8264aed34c42eb9df412b8e4daf995",
            "value": "0000.parquet: 100%"
          }
        },
        "b3fa0777019a4cab92e06be77fa536af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4aabc12b3684fb69f37cabb28d0fd89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b58e20d6ddf34cd28ac7ffdc26021bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5cfbcb650754fe88e7d7ca6d320e2a0",
            "placeholder": "​",
            "style": "IPY_MODEL_2c78047dd5b74558953fa36993b3c179",
            "value": " 504M/504M [00:02&lt;00:00, 254MB/s]"
          }
        },
        "b66026dd389e4994a3b151ea42c7a7ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6674ce2991047e3bf47eacfa18d6821": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b781e68bd28a4a42aeec5b869310b78d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b86b6951532c482ca779bccbeca6f1fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b878b9187713438baa67ee369e36f26e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8b85077749c47eba9403125bc724b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_542abbdafed54d5983937529f8e88b78",
            "max": 511840780,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ea440359b1b42d190445de68d0b34b2",
            "value": 511840780
          }
        },
        "b97bb17615f049a8a91e128d6048caa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcb5713817e64e5d9c2cefbd420faf3c",
            "placeholder": "​",
            "style": "IPY_MODEL_9a55b9689e5a45f1b8015f6ead02af1f",
            "value": "README.md: 100%"
          }
        },
        "bcb5713817e64e5d9c2cefbd420faf3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd4adefd6cbc49b4a56ea16f47a376e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdd67c725d3543f3a83926496d5e29f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be622481a5de458eb919b2ef7b0471fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be8699711c924eb68139c574c0088659": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bef2e5053b3e417ba47efb69473b6cc4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf2bbda514fd4228985a69169897a56e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d635c3050de84ba39f9a5452f9a39fda",
              "IPY_MODEL_96874952db58467e9967c5a4c92c39f8",
              "IPY_MODEL_b58e20d6ddf34cd28ac7ffdc26021bb9"
            ],
            "layout": "IPY_MODEL_5ec351887a5f407294a18b69df02de98"
          }
        },
        "c0d3795ca6554386a1798136403f6e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0fd101ec4824a50ad26c1c3f899b216": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1e9631acf9b4563924da55fbc5a8b28": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1f405116e244128ba592fd13fedc605": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3bb9b8015594bb7a2ad63f52f4672cb",
            "placeholder": "​",
            "style": "IPY_MODEL_307d8551854744ff8f616c97a978d9b9",
            "value": " 96.3M/96.3M [00:00&lt;00:00, 155MB/s]"
          }
        },
        "c5cfbcb650754fe88e7d7ca6d320e2a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c923b45bcf624511b33150cf433088a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_113bc7413aec4e1db4ec9248dccd68ee",
            "max": 1250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2dd9362ff0b8406785180655c753bceb",
            "value": 1250
          }
        },
        "ca8264aed34c42eb9df412b8e4daf995": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0d712516fd94c02a6df6ecaf2d42a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11078b8185bb4c7c98ec0ba7a6b7af97",
            "placeholder": "​",
            "style": "IPY_MODEL_3d83e81f8923486eaba0b6f8ace3d96d",
            "value": " 506M/506M [00:03&lt;00:00, 145MB/s]"
          }
        },
        "d12e7fd4fcff4275bea3575a285eedf9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d42de8800e9b41a58364f1abda3010ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d635c3050de84ba39f9a5452f9a39fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68e79979ba5845898ef147d1d3087c77",
            "placeholder": "​",
            "style": "IPY_MODEL_557ff2778e90430cac290b98631b75d1",
            "value": "0004.parquet: 100%"
          }
        },
        "d7dc61325d7949bfbe2451d5ded4ed59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8d452526fd641eda93d51280dee8601": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d98782a0af6d40a69b4a89080a2b9fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e3571256867403891eab79267038e85",
              "IPY_MODEL_b8b85077749c47eba9403125bc724b4d",
              "IPY_MODEL_37ffc1c73650480882ebb55918a98837"
            ],
            "layout": "IPY_MODEL_6b497aed398349859b27564fb9fb8387"
          }
        },
        "db66ad84f6e746db8f81f6b01f168cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd4adefd6cbc49b4a56ea16f47a376e2",
            "placeholder": "​",
            "style": "IPY_MODEL_b6674ce2991047e3bf47eacfa18d6821",
            "value": "0008.parquet: 100%"
          }
        },
        "de212cb8bb114212b0d3ebbb7df08f39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e026a886ded141dcbd5af167beb354ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e06613869dff468aa5c33c5fcf77bc74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1a4ec72204145169b39bf265a8f3ff3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e23406134bfb4d60b158d01e112519c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e31f661a649d4b4e80196c9f22774beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bef2e5053b3e417ba47efb69473b6cc4",
            "placeholder": "​",
            "style": "IPY_MODEL_761952237a8e4cf7ada1b65d6e88853a",
            "value": "README.md: 100%"
          }
        },
        "e3a68d96b0594f9cbdb117011091f1aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3bb9b8015594bb7a2ad63f52f4672cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e43b648e2c154c16808ca06b66e493e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b164df86fc3a46e08ef36691e276ca65",
              "IPY_MODEL_85dffbb4d9a14d3c8f9e907553596252",
              "IPY_MODEL_d0d712516fd94c02a6df6ecaf2d42a87"
            ],
            "layout": "IPY_MODEL_b3fa0777019a4cab92e06be77fa536af"
          }
        },
        "e4ddc8062d6d4a0794dac8e97f9b4803": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b781e68bd28a4a42aeec5b869310b78d",
            "placeholder": "​",
            "style": "IPY_MODEL_61b42c4af0854535a5488f60c87e7e81",
            "value": " 495M/495M [00:03&lt;00:00, 105MB/s]"
          }
        },
        "e8cbb6f8f71a496f9db0f8c8860286af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecf1ea95e4ba481a8766f2a17ae53852": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee464f3916724bde8959393f4f5469b6",
            "placeholder": "​",
            "style": "IPY_MODEL_4f4acdaaf4bb4fb3a912cd315370c10d",
            "value": "0001.parquet: 100%"
          }
        },
        "ee275536a6b4441bb6e934cdf72b564a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee464f3916724bde8959393f4f5469b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef1f8e91f41447318865eb2618bdd81a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f05fded6f55e4dbc9dc4cf4690904684": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f67440eef6dc4eceab0c2b5d72f0f0c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9bb9f950a08461bb80960116bf9a994": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07bada43d40f48c59ddda3c6068a358a",
            "placeholder": "​",
            "style": "IPY_MODEL_be8699711c924eb68139c574c0088659",
            "value": " 1250/1250 [00:00&lt;00:00, 1997.17 examples/s]"
          }
        },
        "fc2617cba8904280963986b43184cfec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff964d64bb77429da3dec0c8f140e025": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
